{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tuesmonsoleil/Dysgraphia-Classification/blob/main/0414.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XPm-SkN8aVzV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOy_gbyzaeWn",
        "outputId": "f5644477-cedb-4bbb-ca03-dc32a8c6c8ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['test', 'train', 'dataset']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Define data directory\n",
        "data_dir = \"train\"\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "Dataset = os.chdir('/content/drive/My Drive/Dataset/dataSciRep_public') #切換該目錄\n",
        "os.listdir() #確認目錄內容"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unXnIsLUaf92",
        "outputId": "84d306f6-5e61-4468-c4ce-5f32268c3285"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: protobuf==3.20.3 in /usr/local/lib/python3.10/dist-packages (3.20.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (1.14.0)\n",
            "Requirement already satisfied: absl-py<2.0.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata) (1.4.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata) (1.63.0)\n",
            "Requirement already satisfied: protobuf<4.21,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata) (3.20.3)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.1/330.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 4.25.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install protobuf==3.20.3\n",
        "!pip install --upgrade tensorflow-metadata\n",
        "!pip install -q flwr[simulation] torch torchvision scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "m3kodGQFanBP"
      },
      "outputs": [],
      "source": [
        "!pip install -q flwr[simulation] torch torchvision scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXKzQh42aqCJ",
        "outputId": "6adeef7c-3be1-40d8-d9cb-e524e4fdd105"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on cpu using PyTorch 2.2.1+cu121 and Flower 1.8.0\n"
          ]
        }
      ],
      "source": [
        "from collections import OrderedDict\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.datasets import CIFAR10\n",
        "import flwr as fl\n",
        "\n",
        "DEVICE = torch.device(\"cpu\")  # Try \"cuda\" to train on GPU\n",
        "print(\n",
        "    f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BXiVWjqarHS",
        "outputId": "df738006-15fb-4607-b597-6346ac37f0d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "NUM_CLIENTS = 2\n",
        "\n",
        "def load_datasets(num_clients: int):\n",
        "    # Download and transform CIFAR-10 (train and test)\n",
        "    transform = transforms.Compose(\n",
        "        [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        "    )\n",
        "    trainset = CIFAR10(\"./dataset\", train=True, download=True, transform=transform)\n",
        "    testset = CIFAR10(\"./dataset\", train=False, download=True, transform=transform)\n",
        "\n",
        "    # Split training set into `num_clients` partitions to simulate different local datasets\n",
        "    partition_size = len(trainset) // num_clients\n",
        "    lengths = [partition_size] * num_clients\n",
        "    datasets = random_split(trainset, lengths, torch.Generator().manual_seed(42))\n",
        "\n",
        "    # Split each partition into train/val and create DataLoader\n",
        "    trainloaders = []\n",
        "    valloaders = []\n",
        "    for ds in datasets:\n",
        "        len_val = len(ds) // 10  # 10 % validation set\n",
        "        len_train = len(ds) - len_val\n",
        "        lengths = [len_train, len_val]\n",
        "        ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
        "        trainloaders.append(DataLoader(ds_train, batch_size=30, shuffle=True))\n",
        "        valloaders.append(DataLoader(ds_val, batch_size=30))\n",
        "    testloader = DataLoader(testset, batch_size=30)\n",
        "    return trainloaders, valloaders, testloader\n",
        "\n",
        "\n",
        "trainloaders, valloaders, testloader = load_datasets(NUM_CLIENTS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "F1DSNaA0avTM"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def get_parameters(net) -> List[np.ndarray]:\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
        "\n",
        "\n",
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "\n",
        "def train(net, trainloader, epochs: int):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters())\n",
        "    net.train()\n",
        "    for epoch in range(epochs):\n",
        "        correct, total, epoch_loss = 0, 0, 0.0\n",
        "        for images, labels in trainloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(images)\n",
        "            loss = criterion(net(images), labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # Metrics\n",
        "            epoch_loss += loss\n",
        "            total += labels.size(0)\n",
        "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "        epoch_loss /= len(trainloader.dataset)\n",
        "        epoch_acc = correct / total\n",
        "        print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
        "\n",
        "\n",
        "def test(net, testloader):\n",
        "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    loss /= len(testloader.dataset)\n",
        "    accuracy = correct / total\n",
        "    return loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Lf2GcVrfaxCn"
      },
      "outputs": [],
      "source": [
        "class FlowerNumPyClient(fl.client.NumPyClient):\n",
        "    def __init__(self, cid, net, trainloader, valloader):\n",
        "        self.cid = cid\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        print(f\"[Client {self.cid}] get_parameters\")\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        print(f\"[Client {self.cid}] fit, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        train(self.net, self.trainloader, epochs=15)\n",
        "        return get_parameters(self.net), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        loss, accuracy = test(self.net, self.valloader)\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
        "\n",
        "\n",
        "def numpyclient_fn(cid) -> FlowerNumPyClient:\n",
        "    net = Net().to(DEVICE)\n",
        "    trainloader = trainloaders[int(cid)]\n",
        "    valloader = valloaders[int(cid)]\n",
        "    return FlowerNumPyClient(cid, net, trainloader, valloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDixMds-axiB",
        "outputId": "f022f66f-b411-406e-ca80-e1dcda6f35c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=3, no round_timeout\n",
            "INFO:flwr:Starting Flower simulation, config: num_rounds=3, no round_timeout\n",
            "/usr/lib/python3.10/subprocess.py:1796: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = _posixsubprocess.fork_exec(\n",
            "2024-04-14 07:11:24,071\tINFO worker.py:1621 -- Started a local Ray instance.\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'CPU': 2.0, 'object_store_memory': 3945402777.0, 'memory': 7890805556.0, 'node:__internal_head__': 1.0, 'GPU': 1.0, 'node:172.28.0.12': 1.0}\n",
            "INFO:flwr:Flower VCE: Ray initialized with resources: {'CPU': 2.0, 'object_store_memory': 3945402777.0, 'memory': 7890805556.0, 'node:__internal_head__': 1.0, 'GPU': 1.0, 'node:172.28.0.12': 1.0}\n",
            "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
            "INFO:flwr:Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
            "\u001b[92mINFO \u001b[0m:      No `client_resources` specified. Using minimal resources for clients.\n",
            "INFO:flwr:No `client_resources` specified. Using minimal resources for clients.\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
            "INFO:flwr:Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n",
            "INFO:flwr:Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n",
            "\u001b[92mINFO \u001b[0m:      [INIT]\n",
            "INFO:flwr:[INIT]\n",
            "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
            "INFO:flwr:Requesting initial parameters from one random client\n",
            "\u001b[2m\u001b[36m(pid=2338)\u001b[0m 2024-04-14 07:11:30.974453: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=2338)\u001b[0m 2024-04-14 07:11:30.974513: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=2338)\u001b[0m 2024-04-14 07:11:30.978271: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=2338)\u001b[0m 2024-04-14 07:11:33.365690: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
            "INFO:flwr:Received initial parameters from one random client\n",
            "\u001b[92mINFO \u001b[0m:      Evaluating initial global parameters\n",
            "INFO:flwr:Evaluating initial global parameters\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[2m\u001b[36m(pid=2337)\u001b[0m 2024-04-14 07:11:31.090198: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=2337)\u001b[0m 2024-04-14 07:11:31.090252: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=2337)\u001b[0m 2024-04-14 07:11:31.094468: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=2337)\u001b[0m 2024-04-14 07:11:33.418313: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO:flwr:[ROUND 1]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "INFO:flwr:configure_fit: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m [Client 0] get_parameters\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m [Client 0] fit, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=2337)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=2337)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m Epoch 1: train loss 0.05784803628921509, accuracy 0.3607111111111111\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2337)\u001b[0m Epoch 1: train loss 0.05802883207798004, accuracy 0.3489333333333333\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m Epoch 2: train loss 0.04809747636318207, accuracy 0.4769333333333333\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2337)\u001b[0m Epoch 2: train loss 0.04896329715847969, accuracy 0.4634666666666667\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m Epoch 3: train loss 0.0439232736825943, accuracy 0.5258666666666667\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2337)\u001b[0m Epoch 3: train loss 0.04504499211907387, accuracy 0.5100888888888889\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m Epoch 4: train loss 0.04094505310058594, accuracy 0.5582222222222222\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2337)\u001b[0m Epoch 4: train loss 0.042088475078344345, accuracy 0.5452444444444444\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m Epoch 5: train loss 0.03864947333931923, accuracy 0.5832444444444445\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2337)\u001b[0m Epoch 5: train loss 0.039558518677949905, accuracy 0.5754666666666667\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m Epoch 6: train loss 0.036373239010572433, accuracy 0.6100444444444444\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2337)\u001b[0m Epoch 6: train loss 0.037509188055992126, accuracy 0.5999111111111111\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m Epoch 7: train loss 0.03437798097729683, accuracy 0.6302666666666666\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2337)\u001b[0m Epoch 7: train loss 0.035285744816064835, accuracy 0.6241777777777778\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m Epoch 8: train loss 0.03279734030365944, accuracy 0.6502666666666667\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2337)\u001b[0m Epoch 8: train loss 0.033379532396793365, accuracy 0.6444444444444445\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m Epoch 9: train loss 0.03098362125456333, accuracy 0.6676444444444445\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2337)\u001b[0m Epoch 9: train loss 0.03158960118889809, accuracy 0.6642666666666667\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m Epoch 10: train loss 0.029462642967700958, accuracy 0.6856888888888889\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2337)\u001b[0m Epoch 10: train loss 0.030225170776247978, accuracy 0.68\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m Epoch 11: train loss 0.027975929901003838, accuracy 0.6986666666666667\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2337)\u001b[0m Epoch 11: train loss 0.028571007773280144, accuracy 0.6952888888888888\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m Epoch 12: train loss 0.02629602514207363, accuracy 0.7171555555555555\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2337)\u001b[0m Epoch 12: train loss 0.02729296311736107, accuracy 0.7085333333333333\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m Epoch 13: train loss 0.025093574076890945, accuracy 0.7329333333333333\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2337)\u001b[0m Epoch 13: train loss 0.026021378114819527, accuracy 0.7200444444444445\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m Epoch 14: train loss 0.023979755118489265, accuracy 0.7440888888888889\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2337)\u001b[0m Epoch 14: train loss 0.024724474176764488, accuracy 0.7389777777777777\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m Epoch 15: train loss 0.022416429594159126, accuracy 0.7626666666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No fit_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=2337)\u001b[0m Epoch 15: train loss 0.023439548909664154, accuracy 0.7472888888888889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=2337)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=2337)\u001b[0m [Client 0] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No evaluate_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No evaluate_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
            "INFO:flwr:[ROUND 2]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "INFO:flwr:configure_fit: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m Epoch 1: train loss 0.03645361214876175, accuracy 0.6104888888888889\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2337)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m Epoch 2: train loss 0.03143057972192764, accuracy 0.6642222222222223\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m Epoch 3: train loss 0.028657719492912292, accuracy 0.6944\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m Epoch 4: train loss 0.02640824019908905, accuracy 0.7170666666666666\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m Epoch 5: train loss 0.02438557893037796, accuracy 0.7384444444444445\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m Epoch 6: train loss 0.022400490939617157, accuracy 0.7622222222222222\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m Epoch 7: train loss 0.020487546920776367, accuracy 0.7811111111111111\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m Epoch 8: train loss 0.019119257107377052, accuracy 0.7960888888888888\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m Epoch 9: train loss 0.01732982136309147, accuracy 0.814\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m Epoch 10: train loss 0.015991318970918655, accuracy 0.8286666666666667\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m Epoch 11: train loss 0.014340931549668312, accuracy 0.8459111111111111\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m Epoch 12: train loss 0.013529368676245213, accuracy 0.8537777777777777\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m Epoch 13: train loss 0.012361188419163227, accuracy 0.8654666666666667\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m Epoch 14: train loss 0.01146330963820219, accuracy 0.8764444444444445\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m Epoch 15: train loss 0.010143277235329151, accuracy 0.8906222222222222\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2337)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=2337)\u001b[0m [Client 1] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
            "INFO:flwr:[ROUND 3]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "INFO:flwr:configure_fit: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2337)\u001b[0m Epoch 15: train loss 0.009672188200056553, accuracy 0.8976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=2337)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m Epoch 1: train loss 0.03019244782626629, accuracy 0.6840888888888889\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2337)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m Epoch 2: train loss 0.022440873086452484, accuracy 0.7565777777777778\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m Epoch 3: train loss 0.018905984237790108, accuracy 0.7947555555555555\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m Epoch 4: train loss 0.01620139181613922, accuracy 0.8231555555555555\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m Epoch 5: train loss 0.014330288395285606, accuracy 0.8455111111111111\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m Epoch 6: train loss 0.012641800567507744, accuracy 0.8628888888888889\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m Epoch 7: train loss 0.011594908311963081, accuracy 0.8772444444444445\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m Epoch 8: train loss 0.009873694740235806, accuracy 0.8953777777777778\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m Epoch 9: train loss 0.009508765302598476, accuracy 0.8982666666666667\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m Epoch 10: train loss 0.00858299806714058, accuracy 0.9058666666666667\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m Epoch 11: train loss 0.007892671972513199, accuracy 0.9142222222222223\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m Epoch 12: train loss 0.007124330848455429, accuracy 0.9237333333333333\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m Epoch 13: train loss 0.0067031909711658955, accuracy 0.9289777777777778\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m Epoch 14: train loss 0.0062405443750321865, accuracy 0.9342222222222222\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m Epoch 15: train loss 0.005771355703473091, accuracy 0.9375555555555556\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2337)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=2337)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=2337)\u001b[0m Epoch 15: train loss 0.006008152849972248, accuracy 0.9371555555555555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=2338)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
            "INFO:flwr:[SUMMARY]\n",
            "\u001b[92mINFO \u001b[0m:      Run finished 3 rounds in 1149.48s\n",
            "INFO:flwr:Run finished 3 rounds in 1149.48s\n",
            "\u001b[92mINFO \u001b[0m:      History (loss, distributed):\n",
            "INFO:flwr:History (loss, distributed):\n",
            "\u001b[92mINFO \u001b[0m:      \t('\\tround 1: 0.04803205106258393\\n'\n",
            "INFO:flwr:\t('\\tround 1: 0.04803205106258393\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 2: 0.05861795074641705\\n'\n",
            "INFO:flwr:\t '\\tround 2: 0.05861795074641705\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 3: 0.0791682706207037\\n')\n",
            "INFO:flwr:\t '\\tround 3: 0.0791682706207037\\n')\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n"
          ]
        }
      ],
      "source": [
        "# Specify client resources if you need GPU (defaults to 1 CPU and 0 GPU)\n",
        "client_resources = None\n",
        "if DEVICE.type == \"cuda\":\n",
        "    client_resources = {\"num_gpus\": 1}\n",
        "\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=numpyclient_fn,\n",
        "    num_clients=2,\n",
        "    config=fl.server.ServerConfig(num_rounds=3),\n",
        "    client_resources=client_resources,\n",
        ")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def train(net, trainloader, epochs: int):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters())\n",
        "    net.train()\n",
        "\n",
        "    # Initialize lists to store training loss and accuracy\n",
        "    train_losses = []\n",
        "    train_accuracies = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        correct, total, epoch_loss = 0, 0, 0.0\n",
        "        for images, labels in trainloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(images)\n",
        "            loss = criterion(net(images), labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # Metrics\n",
        "            epoch_loss += loss\n",
        "            total += labels.size(0)\n",
        "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "\n",
        "        # Calculate and store training accuracy for this epoch\n",
        "        epoch_loss /= len(trainloader.dataset)\n",
        "        epoch_acc = correct / total\n",
        "        train_losses.append(epoch_loss)\n",
        "        train_accuracies.append(epoch_acc)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KshN7Dxza0c7",
        "outputId": "130e270c-f5a3-4ebc-9e3f-1cd91996cae6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=4, no round_timeout\n",
            "INFO:flwr:Starting Flower simulation, config: num_rounds=4, no round_timeout\n",
            "/usr/lib/python3.10/subprocess.py:1796: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = _posixsubprocess.fork_exec(\n",
            "2024-04-14 07:30:53,484\tINFO worker.py:1621 -- Started a local Ray instance.\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'memory': 7821611828.0, 'CPU': 2.0, 'node:__internal_head__': 1.0, 'object_store_memory': 3910805913.0, 'GPU': 1.0, 'node:172.28.0.12': 1.0}\n",
            "INFO:flwr:Flower VCE: Ray initialized with resources: {'memory': 7821611828.0, 'CPU': 2.0, 'node:__internal_head__': 1.0, 'object_store_memory': 3910805913.0, 'GPU': 1.0, 'node:172.28.0.12': 1.0}\n",
            "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
            "INFO:flwr:Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
            "\u001b[92mINFO \u001b[0m:      No `client_resources` specified. Using minimal resources for clients.\n",
            "INFO:flwr:No `client_resources` specified. Using minimal resources for clients.\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
            "INFO:flwr:Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n",
            "INFO:flwr:Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n",
            "\u001b[92mINFO \u001b[0m:      [INIT]\n",
            "INFO:flwr:[INIT]\n",
            "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
            "INFO:flwr:Requesting initial parameters from one random client\n",
            "\u001b[2m\u001b[36m(pid=7435)\u001b[0m 2024-04-14 07:30:59.145844: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=7435)\u001b[0m 2024-04-14 07:30:59.145889: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=7435)\u001b[0m 2024-04-14 07:30:59.149376: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=7436)\u001b[0m 2024-04-14 07:31:02.038323: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
            "INFO:flwr:Received initial parameters from one random client\n",
            "\u001b[92mINFO \u001b[0m:      Evaluating initial global parameters\n",
            "INFO:flwr:Evaluating initial global parameters\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
            "INFO:flwr:[ROUND 1]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "INFO:flwr:configure_fit: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=7436)\u001b[0m [Client 0] get_parameters\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7436)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7435)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7436)\u001b[0m Epoch 1: train loss 0.05841486155986786, accuracy 0.35635555555555554\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7435)\u001b[0m Epoch 1: train loss 0.05898568779230118, accuracy 0.34542222222222224\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7436)\u001b[0m Epoch 2: train loss 0.0482713058590889, accuracy 0.47173333333333334\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7435)\u001b[0m Epoch 2: train loss 0.049218762665987015, accuracy 0.4646222222222222\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7436)\u001b[0m Epoch 3: train loss 0.04404629021883011, accuracy 0.5234222222222222\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7435)\u001b[0m Epoch 3: train loss 0.04499850049614906, accuracy 0.5170666666666667\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7436)\u001b[0m Epoch 4: train loss 0.040911853313446045, accuracy 0.5633333333333334\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7435)\u001b[0m Epoch 4: train loss 0.041596926748752594, accuracy 0.5532444444444444\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7436)\u001b[0m Epoch 5: train loss 0.038341689854860306, accuracy 0.5924444444444444\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7435)\u001b[0m Epoch 5: train loss 0.03884955868124962, accuracy 0.5853777777777778\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7436)\u001b[0m Epoch 6: train loss 0.03613169118762016, accuracy 0.6170666666666667\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7435)\u001b[0m Epoch 6: train loss 0.03684538975358009, accuracy 0.6067111111111111\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7436)\u001b[0m Epoch 7: train loss 0.034206945449113846, accuracy 0.6344888888888889\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7435)\u001b[0m Epoch 7: train loss 0.03468431159853935, accuracy 0.6311555555555556\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7436)\u001b[0m Epoch 8: train loss 0.0328386090695858, accuracy 0.6517777777777778\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7435)\u001b[0m Epoch 8: train loss 0.03305060416460037, accuracy 0.6468444444444444\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7436)\u001b[0m Epoch 9: train loss 0.031053250655531883, accuracy 0.6705333333333333\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7435)\u001b[0m Epoch 9: train loss 0.03140559047460556, accuracy 0.6645777777777778\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7436)\u001b[0m Epoch 10: train loss 0.029432056471705437, accuracy 0.6875555555555556\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7435)\u001b[0m Epoch 10: train loss 0.029897280037403107, accuracy 0.6800888888888889\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7436)\u001b[0m Epoch 11: train loss 0.02816145494580269, accuracy 0.7002222222222222\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7435)\u001b[0m Epoch 11: train loss 0.028372272849082947, accuracy 0.6982666666666667\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7436)\u001b[0m Epoch 12: train loss 0.026683680713176727, accuracy 0.7169777777777778\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7435)\u001b[0m Epoch 12: train loss 0.026859749108552933, accuracy 0.7162666666666667\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7436)\u001b[0m Epoch 13: train loss 0.025473862886428833, accuracy 0.7284444444444444\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7435)\u001b[0m Epoch 13: train loss 0.025495367124676704, accuracy 0.7282666666666666\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7436)\u001b[0m Epoch 14: train loss 0.024405211210250854, accuracy 0.7390666666666666\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7435)\u001b[0m Epoch 14: train loss 0.02410639077425003, accuracy 0.7450666666666667\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7436)\u001b[0m Epoch 15: train loss 0.023016221821308136, accuracy 0.7532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No fit_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=7435)\u001b[0m Epoch 15: train loss 0.022691208869218826, accuracy 0.7584888888888889\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7435)\u001b[0m [Client 0] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No evaluate_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No evaluate_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
            "INFO:flwr:[ROUND 2]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "INFO:flwr:configure_fit: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=7436)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7436)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7436)\u001b[0m Epoch 1: train loss 0.037607889622449875, accuracy 0.6004\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7435)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7436)\u001b[0m Epoch 2: train loss 0.03220457211136818, accuracy 0.6552444444444444\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7435)\u001b[0m Epoch 3: train loss 0.02887336164712906, accuracy 0.6920888888888889\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7435)\u001b[0m Epoch 4: train loss 0.02644055150449276, accuracy 0.7169777777777778\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7436)\u001b[0m Epoch 5: train loss 0.024362290278077126, accuracy 0.7375555555555555\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7436)\u001b[0m Epoch 6: train loss 0.022186914458870888, accuracy 0.7628\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7436)\u001b[0m Epoch 7: train loss 0.020309172570705414, accuracy 0.7812888888888889\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7436)\u001b[0m Epoch 8: train loss 0.01849130354821682, accuracy 0.8011555555555555\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7436)\u001b[0m Epoch 9: train loss 0.01694326661527157, accuracy 0.8214222222222223\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7436)\u001b[0m Epoch 10: train loss 0.015377833507955074, accuracy 0.8345333333333333\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7436)\u001b[0m Epoch 11: train loss 0.013684993609786034, accuracy 0.8523111111111111\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7436)\u001b[0m Epoch 12: train loss 0.012728635221719742, accuracy 0.8631555555555556\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7436)\u001b[0m Epoch 13: train loss 0.011456997133791447, accuracy 0.8774222222222222\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7436)\u001b[0m Epoch 14: train loss 0.01063389889895916, accuracy 0.8857333333333334\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7436)\u001b[0m Epoch 15: train loss 0.009732170030474663, accuracy 0.896\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=7435)\u001b[0m [Client 1] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
            "INFO:flwr:[ROUND 3]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "INFO:flwr:configure_fit: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=7436)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7435)\u001b[0m Epoch 15: train loss 0.010031881742179394, accuracy 0.8935111111111111\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7436)\u001b[0m Epoch 1: train loss 0.030078234151005745, accuracy 0.6832888888888888\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7436)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7435)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7436)\u001b[0m Epoch 2: train loss 0.02237863838672638, accuracy 0.756\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7436)\u001b[0m Epoch 3: train loss 0.018580419942736626, accuracy 0.7975555555555556\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7436)\u001b[0m Epoch 4: train loss 0.015970544889569283, accuracy 0.8267111111111111\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7436)\u001b[0m Epoch 5: train loss 0.013782445341348648, accuracy 0.8504888888888888\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7436)\u001b[0m Epoch 6: train loss 0.012243306264281273, accuracy 0.8669777777777777\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7435)\u001b[0m Epoch 7: train loss 0.010710470378398895, accuracy 0.8828888888888888\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7435)\u001b[0m Epoch 8: train loss 0.0097693195566535, accuracy 0.8948\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7435)\u001b[0m Epoch 9: train loss 0.008326639421284199, accuracy 0.9102666666666667\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7435)\u001b[0m Epoch 10: train loss 0.008065166883170605, accuracy 0.9144\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7435)\u001b[0m Epoch 11: train loss 0.007394817657768726, accuracy 0.9219111111111111\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7435)\u001b[0m Epoch 12: train loss 0.006721883080899715, accuracy 0.9276\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7435)\u001b[0m Epoch 13: train loss 0.006021841894835234, accuracy 0.9355111111111111\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7435)\u001b[0m Epoch 14: train loss 0.006119856145232916, accuracy 0.9339111111111111\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7435)\u001b[0m Epoch 15: train loss 0.00590796722099185, accuracy 0.9380888888888889\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=7436)\u001b[0m [Client 0] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
            "INFO:flwr:[ROUND 4]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "INFO:flwr:configure_fit: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=7435)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7436)\u001b[0m Epoch 15: train loss 0.005815357901155949, accuracy 0.9380888888888889\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7435)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7435)\u001b[0m Epoch 1: train loss 0.028248196467757225, accuracy 0.7166666666666667\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7436)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7435)\u001b[0m Epoch 2: train loss 0.01758827455341816, accuracy 0.8062222222222222\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7435)\u001b[0m Epoch 3: train loss 0.013150186277925968, accuracy 0.8585333333333334\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7435)\u001b[0m Epoch 4: train loss 0.010333267040550709, accuracy 0.8879111111111111\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7435)\u001b[0m Epoch 5: train loss 0.009055918082594872, accuracy 0.9009777777777778\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7435)\u001b[0m Epoch 6: train loss 0.00798238255083561, accuracy 0.9132888888888889\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7435)\u001b[0m Epoch 7: train loss 0.007035344839096069, accuracy 0.9235555555555556\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7435)\u001b[0m Epoch 8: train loss 0.006309595424681902, accuracy 0.9313777777777777\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7435)\u001b[0m Epoch 9: train loss 0.006109762936830521, accuracy 0.9342666666666667\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7435)\u001b[0m Epoch 10: train loss 0.005692467093467712, accuracy 0.9389777777777778\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7435)\u001b[0m Epoch 11: train loss 0.005054668057709932, accuracy 0.9455111111111111\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7435)\u001b[0m Epoch 12: train loss 0.004873079247772694, accuracy 0.9484444444444444\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7435)\u001b[0m Epoch 13: train loss 0.005152256228029728, accuracy 0.9455555555555556\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7435)\u001b[0m Epoch 14: train loss 0.004595013801008463, accuracy 0.9512\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=7435)\u001b[0m Epoch 15: train loss 0.004779402166604996, accuracy 0.9505333333333333\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=7436)\u001b[0m [Client 0] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
            "INFO:flwr:[SUMMARY]\n",
            "\u001b[92mINFO \u001b[0m:      Run finished 4 rounds in 1546.43s\n",
            "INFO:flwr:Run finished 4 rounds in 1546.43s\n",
            "\u001b[92mINFO \u001b[0m:      History (loss, distributed):\n",
            "INFO:flwr:History (loss, distributed):\n",
            "\u001b[92mINFO \u001b[0m:      \t('\\tround 1: 0.04903045078516006\\n'\n",
            "INFO:flwr:\t('\\tround 1: 0.04903045078516006\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 2: 0.0563622995197773\\n'\n",
            "INFO:flwr:\t '\\tround 2: 0.0563622995197773\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 3: 0.0806571910560131\\n'\n",
            "INFO:flwr:\t '\\tround 3: 0.0806571910560131\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 4: 0.0969391125023365\\n')\n",
            "INFO:flwr:\t '\\tround 4: 0.0969391125023365\\n')\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "History (loss, distributed):\n",
              "('\\tround 1: 0.04903045078516006\\n'\n",
              " '\\tround 2: 0.0563622995197773\\n'\n",
              " '\\tround 3: 0.0806571910560131\\n'\n",
              " '\\tround 4: 0.0969391125023365\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "from flwr.common import (\n",
        "    Code,\n",
        "    EvaluateIns,\n",
        "    EvaluateRes,\n",
        "    FitIns,\n",
        "    FitRes,\n",
        "    GetParametersIns,\n",
        "    GetParametersRes,\n",
        "    Status,\n",
        "    ndarrays_to_parameters,\n",
        "    parameters_to_ndarrays,\n",
        ")\n",
        "\n",
        "metrics_list = []\n",
        "class FlowerClient(fl.client.Client):\n",
        "    def __init__(self, cid, net, trainloader, valloader):\n",
        "        self.cid = cid\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "        self.metrics_list = []\n",
        "\n",
        "    def get_parameters(self, ins: GetParametersIns) -> GetParametersRes:\n",
        "        print(f\"[Client {self.cid}] get_parameters\")\n",
        "\n",
        "        # Get parameters as a list of NumPy ndarray's\n",
        "        ndarrays: List[np.ndarray] = get_parameters(self.net)\n",
        "\n",
        "        # Serialize ndarray's into a Parameters object\n",
        "        parameters = ndarrays_to_parameters(ndarrays)\n",
        "\n",
        "        # Build and return response\n",
        "        status = Status(code=Code.OK, message=\"Success\")\n",
        "        return GetParametersRes(\n",
        "            status=status,\n",
        "            parameters=parameters,\n",
        "        )\n",
        "\n",
        "    def fit(self, ins: FitIns) -> FitRes:\n",
        "        print(f\"[Client {self.cid}] fit, config: {ins.config}\")\n",
        "\n",
        "        # Deserialize parameters to NumPy ndarray's\n",
        "        parameters_original = ins.parameters\n",
        "        ndarrays_original = parameters_to_ndarrays(parameters_original)\n",
        "\n",
        "        # Update local model, train, get updated parameters\n",
        "        set_parameters(self.net, ndarrays_original)\n",
        "        train(self.net, self.trainloader, epochs=15)\n",
        "        ndarrays_updated = get_parameters(self.net)\n",
        "\n",
        "        # Serialize ndarray's into a Parameters object\n",
        "        parameters_updated = ndarrays_to_parameters(ndarrays_updated)\n",
        "\n",
        "        # Build and return response\n",
        "        status = Status(code=Code.OK, message=\"Success\")\n",
        "        return FitRes(\n",
        "            status=status,\n",
        "            parameters=parameters_updated,\n",
        "            num_examples=len(self.trainloader),\n",
        "            metrics={},\n",
        "        )\n",
        "\n",
        "    def evaluate(self, ins: EvaluateIns) -> EvaluateRes:\n",
        "        print(f\"[Client {self.cid}] evaluate, config: {ins.config}\")\n",
        "\n",
        "        # Deserialize parameters to NumPy ndarray's\n",
        "        parameters_original = ins.parameters\n",
        "        ndarrays_original = parameters_to_ndarrays(parameters_original)\n",
        "\n",
        "        set_parameters(self.net, ndarrays_original)\n",
        "        loss, accuracy = test(self.net, self.valloader)\n",
        "        # return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
        "\n",
        "        self.metrics_list.append({'accuracy': accuracy, 'loss': loss})\n",
        "\n",
        "        # Build and return response\n",
        "        status = Status(code=Code.OK, message=\"Success\")\n",
        "        return EvaluateRes(\n",
        "            status=status,\n",
        "            loss=float(loss),\n",
        "            num_examples=len(self.valloader),\n",
        "            metrics={\"accuracy\": float(accuracy)},\n",
        "        )\n",
        "\n",
        "\n",
        "def client_fn(cid) -> FlowerClient:\n",
        "    net = Net().to(DEVICE)\n",
        "    trainloader = trainloaders[int(cid)]\n",
        "    valloader = valloaders[int(cid)]\n",
        "    return FlowerClient(cid, net, trainloader, valloader)\n",
        "\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=2,\n",
        "    config=fl.server.ServerConfig(num_rounds=4),\n",
        "    client_resources=client_resources,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4wYm39Za7zH",
        "outputId": "f7a529e3-0d74-4446-ea5c-4bd59184a13b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "class FlowerClient(fl.client.Client):\n",
        "    def __init__(self, cid, net, trainloader, valloader):\n",
        "        self.cid = cid\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "        self.train_losses = []  # 用來儲存訓練損失的列表\n",
        "        self.train_accuracies = []  # 用來儲存訓練準確率的列表\n",
        "\n",
        "    def fit(self, ins: FitIns) -> FitRes:\n",
        "        print(f\"[Client {self.cid}] fit, config: {ins.config}\")\n",
        "\n",
        "        # Deserialize parameters to NumPy ndarray's\n",
        "        parameters_original = ins.parameters\n",
        "        ndarrays_original = parameters_to_ndarrays(parameters_original)\n",
        "\n",
        "        # Update local model, train, get updated parameters\n",
        "        set_parameters(self.net, ndarrays_original)\n",
        "        train(self.net, self.trainloader, epochs=10, client_id=self.cid)\n",
        "        ndarrays_updated = get_parameters(self.net)\n",
        "\n",
        "        # Serialize ndarray's into a Parameters object\n",
        "        parameters_updated = ndarrays_to_parameters(ndarrays_updated)\n",
        "\n",
        "        # Plot training loss and accuracy\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        for i, losses in enumerate(self.train_losses):\n",
        "            plt.plot(range(1, len(losses) + 1), losses, label=f'Epoch {i+1}')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title(f'Client {self.cid} Training Loss')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        for i, accuracies in enumerate(self.train_accuracies):\n",
        "            plt.plot(range(1, len(accuracies) + 1), accuracies, label=f'Epoch {i+1}')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.title(f'Client {self.cid} Training Accuracy')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Build and return response\n",
        "        status = Status(code=Code.OK, message=\"Success\")\n",
        "        return FitRes(\n",
        "            status=status,\n",
        "            parameters=parameters_updated,\n",
        "            num_examples=len(self.trainloader),\n",
        "            metrics={},\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "uphmoKmka-nc"
      },
      "outputs": [],
      "source": [
        "from io import BytesIO\n",
        "from typing import cast\n",
        "import numpy as np\n",
        "from flwr.common.typing import NDArray, NDArrays, Parameters\n",
        "\n",
        "\n",
        "def ndarrays_to_sparse_parameters(ndarrays: NDArrays) -> Parameters:\n",
        "    \"\"\"Convert NumPy ndarrays to parameters object.\"\"\"\n",
        "    tensors = [ndarray_to_sparse_bytes(ndarray) for ndarray in ndarrays]\n",
        "    return Parameters(tensors=tensors, tensor_type=\"numpy.ndarray\")\n",
        "\n",
        "\n",
        "def sparse_parameters_to_ndarrays(parameters: Parameters) -> NDArrays:\n",
        "    \"\"\"Convert parameters object to NumPy ndarrays.\"\"\"\n",
        "    return [sparse_bytes_to_ndarray(tensor) for tensor in parameters.tensors]\n",
        "\n",
        "\n",
        "def ndarray_to_sparse_bytes(ndarray: NDArray) -> bytes:\n",
        "    \"\"\"Serialize NumPy ndarray to bytes.\"\"\"\n",
        "    bytes_io = BytesIO()\n",
        "\n",
        "    if len(ndarray.shape) > 1:\n",
        "        # We convert our ndarray into a sparse matrix\n",
        "        ndarray = torch.tensor(ndarray).to_sparse_csr()\n",
        "\n",
        "        # And send it byutilizing the sparse matrix attributes\n",
        "        # WARNING: NEVER set allow_pickle to true.\n",
        "        # Reason: loading pickled data can execute arbitrary code\n",
        "        # Source: https://numpy.org/doc/stable/reference/generated/numpy.save.html\n",
        "        np.savez(\n",
        "            bytes_io,  # type: ignore\n",
        "            crow_indices=ndarray.crow_indices(),\n",
        "            col_indices=ndarray.col_indices(),\n",
        "            values=ndarray.values(),\n",
        "            allow_pickle=False,\n",
        "        )\n",
        "    else:\n",
        "        # WARNING: NEVER set allow_pickle to true.\n",
        "        # Reason: loading pickled data can execute arbitrary code\n",
        "        # Source: https://numpy.org/doc/stable/reference/generated/numpy.save.html\n",
        "        np.save(bytes_io, ndarray, allow_pickle=False)\n",
        "    return bytes_io.getvalue()\n",
        "\n",
        "\n",
        "def sparse_bytes_to_ndarray(tensor: bytes) -> NDArray:\n",
        "    \"\"\"Deserialize NumPy ndarray from bytes.\"\"\"\n",
        "    bytes_io = BytesIO(tensor)\n",
        "    # WARNING: NEVER set allow_pickle to true.\n",
        "    # Reason: loading pickled data can execute arbitrary code\n",
        "    # Source: https://numpy.org/doc/stable/reference/generated/numpy.load.html\n",
        "    loader = np.load(bytes_io, allow_pickle=False)  # type: ignore\n",
        "\n",
        "    if \"crow_indices\" in loader:\n",
        "        # We convert our sparse matrix back to a ndarray, using the attributes we sent\n",
        "        ndarray_deserialized = (\n",
        "            torch.sparse_csr_tensor(\n",
        "                crow_indices=loader[\"crow_indices\"],\n",
        "                col_indices=loader[\"col_indices\"],\n",
        "                values=loader[\"values\"],\n",
        "            )\n",
        "            .to_dense()\n",
        "            .numpy()\n",
        "        )\n",
        "    else:\n",
        "        ndarray_deserialized = loader\n",
        "    return cast(NDArray, ndarray_deserialized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "wWzlpF4da_mQ"
      },
      "outputs": [],
      "source": [
        "from flwr.common import (\n",
        "    Code,\n",
        "    EvaluateIns,\n",
        "    EvaluateRes,\n",
        "    FitIns,\n",
        "    FitRes,\n",
        "    GetParametersIns,\n",
        "    GetParametersRes,\n",
        "    Status,\n",
        ")\n",
        "\n",
        "class FlowerClient(fl.client.Client):\n",
        "    def __init__(self, cid, net, trainloader, valloader):\n",
        "        self.cid = cid\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "\n",
        "    def get_parameters(self, ins: GetParametersIns) -> GetParametersRes:\n",
        "        print(f\"[Client {self.cid}] get_parameters\")\n",
        "\n",
        "        # Get parameters as a list of NumPy ndarray's\n",
        "        ndarrays: List[np.ndarray] = get_parameters(self.net)\n",
        "\n",
        "        # Serialize ndarray's into a Parameters object using our custom function\n",
        "        parameters = ndarrays_to_sparse_parameters(ndarrays)\n",
        "\n",
        "        # Build and return response\n",
        "        status = Status(code=Code.OK, message=\"Success\")\n",
        "        return GetParametersRes(\n",
        "            status=status,\n",
        "            parameters=parameters,\n",
        "        )\n",
        "\n",
        "    def fit(self, ins: FitIns) -> FitRes:\n",
        "        print(f\"[Client {self.cid}] fit, config: {ins.config}\")\n",
        "\n",
        "        # Deserialize parameters to NumPy ndarray's using our custom function\n",
        "        parameters_original = ins.parameters\n",
        "        ndarrays_original = sparse_parameters_to_ndarrays(parameters_original)\n",
        "\n",
        "        # Update local model, train, get updated parameters\n",
        "        set_parameters(self.net, ndarrays_original)\n",
        "        train(self.net, self.trainloader, epochs=15)\n",
        "        ndarrays_updated = get_parameters(self.net)\n",
        "\n",
        "        # Serialize ndarray's into a Parameters object using our custom function\n",
        "        parameters_updated = ndarrays_to_sparse_parameters(ndarrays_updated)\n",
        "\n",
        "        # Build and return response\n",
        "        status = Status(code=Code.OK, message=\"Success\")\n",
        "        return FitRes(\n",
        "            status=status,\n",
        "            parameters=parameters_updated,\n",
        "            num_examples=len(self.trainloader),\n",
        "            metrics={},\n",
        "        )\n",
        "\n",
        "    def evaluate(self, ins: EvaluateIns) -> EvaluateRes:\n",
        "        print(f\"[Client {self.cid}] evaluate, config: {ins.config}\")\n",
        "\n",
        "        # Deserialize parameters to NumPy ndarray's using our custom function\n",
        "        parameters_original = ins.parameters\n",
        "        ndarrays_original = sparse_parameters_to_ndarrays(parameters_original)\n",
        "\n",
        "        set_parameters(self.net, ndarrays_original)\n",
        "        loss, accuracy = test(self.net, self.valloader)\n",
        "\n",
        "        # Build and return response\n",
        "        status = Status(code=Code.OK, message=\"Success\")\n",
        "        return EvaluateRes(\n",
        "            status=status,\n",
        "            loss=float(loss),\n",
        "            num_examples=len(self.valloader),\n",
        "            metrics={\"accuracy\": float(accuracy)},\n",
        "        )\n",
        "\n",
        "\n",
        "def client_fn(cid) -> FlowerClient:\n",
        "    net = Net().to(DEVICE)\n",
        "    trainloader = trainloaders[int(cid)]\n",
        "    valloader = valloaders[int(cid)]\n",
        "    return FlowerClient(cid, net, trainloader, valloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "tMX-tL62bD1x"
      },
      "outputs": [],
      "source": [
        "from logging import WARNING\n",
        "from typing import Callable, Dict, List, Optional, Tuple, Union\n",
        "\n",
        "from flwr.common import FitRes, MetricsAggregationFn, NDArrays, Parameters, Scalar\n",
        "from flwr.common.logger import log\n",
        "from flwr.server.client_proxy import ClientProxy\n",
        "from flwr.server.strategy import FedAvg\n",
        "from flwr.server.strategy.aggregate import aggregate\n",
        "\n",
        "WARNING_MIN_AVAILABLE_CLIENTS_TOO_LOW = \"\"\"\n",
        "Setting `min_available_clients` lower than `min_fit_clients` or\n",
        "`min_evaluate_clients` can cause the server to fail when there are too few clients\n",
        "connected to the server. `min_available_clients` must be set to a value larger\n",
        "than or equal to the values of `min_fit_clients` and `min_evaluate_clients`.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class FedSparse(FedAvg):\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        fraction_fit: float = 1.0,\n",
        "        fraction_evaluate: float = 1.0,\n",
        "        min_fit_clients: int = 2,\n",
        "        min_evaluate_clients: int = 2,\n",
        "        min_available_clients: int = 2,\n",
        "        evaluate_fn: Optional[\n",
        "            Callable[\n",
        "                [int, NDArrays, Dict[str, Scalar]],\n",
        "                Optional[Tuple[float, Dict[str, Scalar]]],\n",
        "            ]\n",
        "        ] = None,\n",
        "        on_fit_config_fn: Optional[Callable[[int], Dict[str, Scalar]]] = None,\n",
        "        on_evaluate_config_fn: Optional[Callable[[int], Dict[str, Scalar]]] = None,\n",
        "        accept_failures: bool = True,\n",
        "        initial_parameters: Optional[Parameters] = None,\n",
        "        fit_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
        "        evaluate_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
        "    ) -> None:\n",
        "        \"\"\"Custom FedAvg strategy with sparse matrices.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        fraction_fit : float, optional\n",
        "            Fraction of clients used during training. Defaults to 0.1.\n",
        "        fraction_evaluate : float, optional\n",
        "            Fraction of clients used during validation. Defaults to 0.1.\n",
        "        min_fit_clients : int, optional\n",
        "            Minimum number of clients used during training. Defaults to 2.\n",
        "        min_evaluate_clients : int, optional\n",
        "            Minimum number of clients used during validation. Defaults to 2.\n",
        "        min_available_clients : int, optional\n",
        "            Minimum number of total clients in the system. Defaults to 2.\n",
        "        evaluate_fn : Optional[Callable[[int, NDArrays, Dict[str, Scalar]], Optional[Tuple[float, Dict[str, Scalar]]]]]\n",
        "            Optional function used for validation. Defaults to None.\n",
        "        on_fit_config_fn : Callable[[int], Dict[str, Scalar]], optional\n",
        "            Function used to configure training. Defaults to None.\n",
        "        on_evaluate_config_fn : Callable[[int], Dict[str, Scalar]], optional\n",
        "            Function used to configure validation. Defaults to None.\n",
        "        accept_failures : bool, optional\n",
        "            Whether or not accept rounds containing failures. Defaults to True.\n",
        "        initial_parameters : Parameters, optional\n",
        "            Initial global model parameters.\n",
        "        \"\"\"\n",
        "\n",
        "        if (\n",
        "            min_fit_clients > min_available_clients\n",
        "            or min_evaluate_clients > min_available_clients\n",
        "        ):\n",
        "            log(WARNING, WARNING_MIN_AVAILABLE_CLIENTS_TOO_LOW)\n",
        "\n",
        "        super().__init__(\n",
        "            fraction_fit=fraction_fit,\n",
        "            fraction_evaluate=fraction_evaluate,\n",
        "            min_fit_clients=min_fit_clients,\n",
        "            min_evaluate_clients=min_evaluate_clients,\n",
        "            min_available_clients=min_available_clients,\n",
        "            evaluate_fn=evaluate_fn,\n",
        "            on_fit_config_fn=on_fit_config_fn,\n",
        "            on_evaluate_config_fn=on_evaluate_config_fn,\n",
        "            accept_failures=accept_failures,\n",
        "            initial_parameters=initial_parameters,\n",
        "            fit_metrics_aggregation_fn=fit_metrics_aggregation_fn,\n",
        "            evaluate_metrics_aggregation_fn=evaluate_metrics_aggregation_fn,\n",
        "        )\n",
        "\n",
        "    def evaluate(\n",
        "        self, server_round: int, parameters: Parameters\n",
        "    ) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
        "        \"\"\"Evaluate model parameters using an evaluation function.\"\"\"\n",
        "        if self.evaluate_fn is None:\n",
        "            # No evaluation function provided\n",
        "            return None\n",
        "\n",
        "        # We deserialize using our custom method\n",
        "        parameters_ndarrays = sparse_parameters_to_ndarrays(parameters)\n",
        "\n",
        "        eval_res = self.evaluate_fn(server_round, parameters_ndarrays, {})\n",
        "        if eval_res is None:\n",
        "            return None\n",
        "        loss, metrics = eval_res\n",
        "        return loss, metrics\n",
        "\n",
        "    def aggregate_fit(\n",
        "        self,\n",
        "        server_round: int,\n",
        "        results: List[Tuple[ClientProxy, FitRes]],\n",
        "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
        "    ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
        "        \"\"\"Aggregate fit results using weighted average.\"\"\"\n",
        "        if not results:\n",
        "            return None, {}\n",
        "        # Do not aggregate if there are failures and failures are not accepted\n",
        "        if not self.accept_failures and failures:\n",
        "            return None, {}\n",
        "\n",
        "        # We deserialize each of the results with our custom method\n",
        "        weights_results = [\n",
        "            (sparse_parameters_to_ndarrays(fit_res.parameters), fit_res.num_examples)\n",
        "            for _, fit_res in results\n",
        "        ]\n",
        "\n",
        "        # We serialize the aggregated result using our custom method\n",
        "        parameters_aggregated = ndarrays_to_sparse_parameters(\n",
        "            aggregate(weights_results)\n",
        "        )\n",
        "\n",
        "        # Aggregate custom metrics if aggregation fn was provided\n",
        "        metrics_aggregated = {}\n",
        "        if self.fit_metrics_aggregation_fn:\n",
        "            fit_metrics = [(res.num_examples, res.metrics) for _, res in results]\n",
        "            metrics_aggregated = self.fit_metrics_aggregation_fn(fit_metrics)\n",
        "        elif server_round == 1:  # Only log this warning once\n",
        "            log(WARNING, \"No fit_metrics_aggregation_fn provided\")\n",
        "\n",
        "        return parameters_aggregated, metrics_aggregated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e2egg32bFeb",
        "outputId": "ea68d0c0-5cb2-45d2-97b5-d9d3017872bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=4, no round_timeout\n",
            "INFO:flwr:Starting Flower simulation, config: num_rounds=4, no round_timeout\n",
            "/usr/lib/python3.10/subprocess.py:1796: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = _posixsubprocess.fork_exec(\n",
            "2024-04-14 07:56:58,480\tINFO worker.py:1621 -- Started a local Ray instance.\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'GPU': 1.0, 'node:172.28.0.12': 1.0, 'object_store_memory': 3916396953.0, 'node:__internal_head__': 1.0, 'memory': 7832793908.0, 'CPU': 2.0}\n",
            "INFO:flwr:Flower VCE: Ray initialized with resources: {'GPU': 1.0, 'node:172.28.0.12': 1.0, 'object_store_memory': 3916396953.0, 'node:__internal_head__': 1.0, 'memory': 7832793908.0, 'CPU': 2.0}\n",
            "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
            "INFO:flwr:Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
            "\u001b[92mINFO \u001b[0m:      No `client_resources` specified. Using minimal resources for clients.\n",
            "INFO:flwr:No `client_resources` specified. Using minimal resources for clients.\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
            "INFO:flwr:Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n",
            "INFO:flwr:Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n",
            "\u001b[92mINFO \u001b[0m:      [INIT]\n",
            "INFO:flwr:[INIT]\n",
            "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
            "INFO:flwr:Requesting initial parameters from one random client\n",
            "\u001b[2m\u001b[36m(pid=14188)\u001b[0m 2024-04-14 07:57:03.828312: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=14188)\u001b[0m 2024-04-14 07:57:03.828358: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=14188)\u001b[0m 2024-04-14 07:57:03.829939: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=14188)\u001b[0m 2024-04-14 07:57:05.561204: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14188)\u001b[0m <ipython-input-12-fcaae66b064c>:24: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
            "\u001b[2m\u001b[36m(pid=14187)\u001b[0m 2024-04-14 07:57:03.824899: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=14187)\u001b[0m 2024-04-14 07:57:03.824959: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=14187)\u001b[0m 2024-04-14 07:57:03.827064: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=14187)\u001b[0m 2024-04-14 07:57:05.590842: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO:flwr:Received initial parameters from one random client\n",
            "\u001b[92mINFO \u001b[0m:      Evaluating initial global parameters\n",
            "INFO:flwr:Evaluating initial global parameters\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
            "INFO:flwr:[ROUND 1]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "INFO:flwr:configure_fit: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=14188)\u001b[0m [Client 1] get_parameters\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14188)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m [Client 1] fit, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m <ipython-input-12-fcaae66b064c>:56: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=14188)\u001b[0m Epoch 1: train loss 0.059523943811655045, accuracy 0.3432\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 1: train loss 0.05882129445672035, accuracy 0.35044444444444445\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14188)\u001b[0m Epoch 2: train loss 0.04911256581544876, accuracy 0.4653333333333333\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 2: train loss 0.04808470234274864, accuracy 0.47631111111111113\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14188)\u001b[0m Epoch 3: train loss 0.04437166452407837, accuracy 0.5236444444444445\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 3: train loss 0.04356164485216141, accuracy 0.5256444444444445\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14188)\u001b[0m Epoch 4: train loss 0.0411938913166523, accuracy 0.5606666666666666\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 4: train loss 0.040263060480356216, accuracy 0.5668444444444445\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14188)\u001b[0m Epoch 5: train loss 0.03859158232808113, accuracy 0.5883111111111111\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 5: train loss 0.0378202423453331, accuracy 0.5931111111111111\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14188)\u001b[0m Epoch 6: train loss 0.03667335957288742, accuracy 0.6084444444444445\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 6: train loss 0.03589566424489021, accuracy 0.6168444444444444\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14188)\u001b[0m Epoch 7: train loss 0.03476044535636902, accuracy 0.6302666666666666\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 7: train loss 0.033764373511075974, accuracy 0.6368444444444444\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14188)\u001b[0m Epoch 8: train loss 0.032831523567438126, accuracy 0.6530222222222222\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 8: train loss 0.032407935708761215, accuracy 0.6533333333333333\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14188)\u001b[0m Epoch 9: train loss 0.031421221792697906, accuracy 0.6670666666666667\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 9: train loss 0.030644161626696587, accuracy 0.6718666666666666\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14188)\u001b[0m Epoch 10: train loss 0.02973066084086895, accuracy 0.6848444444444445\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 10: train loss 0.029330328106880188, accuracy 0.6860888888888889\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14188)\u001b[0m Epoch 11: train loss 0.02833014540374279, accuracy 0.7010666666666666\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 11: train loss 0.027817966416478157, accuracy 0.7004444444444444\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14188)\u001b[0m Epoch 12: train loss 0.026718461886048317, accuracy 0.7183111111111111\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14188)\u001b[0m Epoch 13: train loss 0.0254303440451622, accuracy 0.728\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14188)\u001b[0m Epoch 14: train loss 0.02436634711921215, accuracy 0.7431111111111111\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14188)\u001b[0m Epoch 15: train loss 0.023050447925925255, accuracy 0.7565333333333333\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 2 results and 0 failures\n",
            "<ipython-input-12-fcaae66b064c>:56: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
            "  torch.sparse_csr_tensor(\n",
            "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No fit_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m [Client 0] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No evaluate_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No evaluate_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
            "INFO:flwr:[ROUND 2]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "INFO:flwr:configure_fit: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=14188)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 15: train loss 0.022624490782618523, accuracy 0.7556444444444445\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14188)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14188)\u001b[0m Epoch 1: train loss 0.038284674286842346, accuracy 0.5903111111111111\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14188)\u001b[0m Epoch 2: train loss 0.032883573323488235, accuracy 0.6505777777777778\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14188)\u001b[0m Epoch 3: train loss 0.02976769208908081, accuracy 0.6852888888888888\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14188)\u001b[0m Epoch 4: train loss 0.026963666081428528, accuracy 0.7146222222222223\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14188)\u001b[0m Epoch 5: train loss 0.024896981194615364, accuracy 0.7363555555555555\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14188)\u001b[0m Epoch 6: train loss 0.022926518693566322, accuracy 0.7589777777777778\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14188)\u001b[0m Epoch 7: train loss 0.021000012755393982, accuracy 0.7776444444444445\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 8: train loss 0.018245145678520203, accuracy 0.8061777777777778\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 9: train loss 0.016607796773314476, accuracy 0.8216888888888889\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 10: train loss 0.015136216767132282, accuracy 0.8352888888888889\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 11: train loss 0.01380365714430809, accuracy 0.8503555555555555\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 12: train loss 0.012624249793589115, accuracy 0.8645777777777778\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 13: train loss 0.011900180019438267, accuracy 0.8709777777777777\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 14: train loss 0.01069068443030119, accuracy 0.8854666666666666\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14188)\u001b[0m Epoch 14: train loss 0.011052691377699375, accuracy 0.8834666666666666\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 15: train loss 0.010252847336232662, accuracy 0.8888444444444444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=14188)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14188)\u001b[0m Epoch 15: train loss 0.010217213071882725, accuracy 0.8892888888888889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
            "INFO:flwr:[ROUND 3]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "INFO:flwr:configure_fit: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 1: train loss 0.030533986166119576, accuracy 0.6819555555555555\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14188)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 2: train loss 0.02291123941540718, accuracy 0.7512\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 3: train loss 0.018974989652633667, accuracy 0.7968\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14188)\u001b[0m Epoch 3: train loss 0.018675126135349274, accuracy 0.7952\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 4: train loss 0.016284899786114693, accuracy 0.8252\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 5: train loss 0.01406612154096365, accuracy 0.8503555555555555\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14188)\u001b[0m Epoch 5: train loss 0.013504640199244022, accuracy 0.8548888888888889\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 6: train loss 0.012481366284191608, accuracy 0.8657333333333334\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14188)\u001b[0m Epoch 6: train loss 0.012398654595017433, accuracy 0.8658666666666667\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 7: train loss 0.011417328380048275, accuracy 0.8768444444444444\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 8: train loss 0.010144743137061596, accuracy 0.8903111111111112\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14188)\u001b[0m Epoch 8: train loss 0.009868312627077103, accuracy 0.8927555555555555\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 9: train loss 0.00925531517714262, accuracy 0.9015555555555556\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14188)\u001b[0m Epoch 9: train loss 0.00901888869702816, accuracy 0.9036444444444445\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 10: train loss 0.00856128241866827, accuracy 0.9079555555555555\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 11: train loss 0.007994330488145351, accuracy 0.9155555555555556\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 12: train loss 0.006917337886989117, accuracy 0.9263555555555556\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 13: train loss 0.006729530170559883, accuracy 0.9275111111111111\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 14: train loss 0.006132588256150484, accuracy 0.9357333333333333\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 15: train loss 0.00630530109629035, accuracy 0.9334222222222223\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=14188)\u001b[0m [Client 1] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
            "INFO:flwr:[ROUND 4]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 2)\n",
            "INFO:flwr:configure_fit: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14188)\u001b[0m Epoch 15: train loss 0.006222890689969063, accuracy 0.9353333333333333\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 1: train loss 0.02818945236504078, accuracy 0.7187555555555556\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14188)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 2: train loss 0.01774362474679947, accuracy 0.8086222222222222\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 3: train loss 0.013424842618405819, accuracy 0.8570666666666666\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 4: train loss 0.010899844579398632, accuracy 0.8788888888888889\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 5: train loss 0.008990239351987839, accuracy 0.9016444444444445\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 6: train loss 0.008393637835979462, accuracy 0.9096\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 7: train loss 0.007149257231503725, accuracy 0.9234666666666667\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 8: train loss 0.0063715605065226555, accuracy 0.9318222222222222\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 9: train loss 0.0058938246220350266, accuracy 0.9386666666666666\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 10: train loss 0.0055989972315728664, accuracy 0.9391111111111111\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 11: train loss 0.005803657229989767, accuracy 0.9370222222222222\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 12: train loss 0.005072630941867828, accuracy 0.9456\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 13: train loss 0.004640747327357531, accuracy 0.9512\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 14: train loss 0.005448106676340103, accuracy 0.9432444444444444\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=14187)\u001b[0m Epoch 15: train loss 0.003915218636393547, accuracy 0.9582222222222222\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 2 clients (out of 2)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=14188)\u001b[0m [Client 0] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 2 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 2 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
            "INFO:flwr:[SUMMARY]\n",
            "\u001b[92mINFO \u001b[0m:      Run finished 4 rounds in 1566.69s\n",
            "INFO:flwr:Run finished 4 rounds in 1566.69s\n",
            "\u001b[92mINFO \u001b[0m:      History (loss, distributed):\n",
            "INFO:flwr:History (loss, distributed):\n",
            "\u001b[92mINFO \u001b[0m:      \t('\\tround 1: 0.053481425690650945\\n'\n",
            "INFO:flwr:\t('\\tround 1: 0.053481425690650945\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 2: 0.055818715357780456\\n'\n",
            "INFO:flwr:\t '\\tround 2: 0.055818715357780456\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 3: 0.07534729050397873\\n'\n",
            "INFO:flwr:\t '\\tround 3: 0.07534729050397873\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 4: 0.09297100775241851\\n')\n",
            "INFO:flwr:\t '\\tround 4: 0.09297100775241851\\n')\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "History (loss, distributed):\n",
              "('\\tround 1: 0.053481425690650945\\n'\n",
              " '\\tround 2: 0.055818715357780456\\n'\n",
              " '\\tround 3: 0.07534729050397873\\n'\n",
              " '\\tround 4: 0.09297100775241851\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "strategy = FedSparse()\n",
        "\n",
        "fl.simulation.start_simulation(\n",
        "    strategy=strategy,\n",
        "    client_fn=client_fn,\n",
        "    num_clients=2,\n",
        "    config=fl.server.ServerConfig(num_rounds=4),\n",
        "    client_resources=client_resources,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-meWk9AtbH2a",
        "outputId": "fca36a94-9595-44db-8570-254556cbf578"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python\n",
        "# -*- coding: utf-8 -*-\n",
        "# Python version: 3.6\n",
        "\n",
        "import torch\n",
        "from torch import nn, autograd\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn import metrics\n",
        "\n",
        "class DatasetSplit(Dataset):\n",
        "    def __init__(self, dataset, idxs):\n",
        "        self.dataset = dataset\n",
        "        self.idxs = list(idxs)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.idxs)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        image, label = self.dataset[self.idxs[item]]\n",
        "        return image, label\n",
        "\n",
        "class LocalUpdate(object):\n",
        "    def __init__(self, args, dataset=None, idxs=None):\n",
        "        self.args = args\n",
        "        self.loss_func = nn.CrossEntropyLoss()\n",
        "        self.selected_clients = []\n",
        "        self.ldr_train = DataLoader(DatasetSplit(dataset, idxs), batch_size=self.args.local_bs, shuffle=True)\n",
        "\n",
        "    def train(self, net):\n",
        "        net.train()\n",
        "        # train and update\n",
        "        optimizer = torch.optim.SGD(net.parameters(), lr=self.args.lr, momentum=self.args.momentum)\n",
        "\n",
        "        epoch_loss = []\n",
        "        for iter in range(self.args.local_ep):\n",
        "            batch_loss = []\n",
        "            for batch_idx, (images, labels) in enumerate(self.ldr_train):\n",
        "                images, labels = images.to(self.args.device), labels.to(self.args.device)\n",
        "                net.zero_grad()\n",
        "                log_probs = net(images)\n",
        "                loss = self.loss_func(log_probs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                if self.args.verbose and batch_idx % 10 == 0:\n",
        "                    print('Update Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                        iter, batch_idx * len(images), len(self.ldr_train.dataset),\n",
        "                               100. * batch_idx / len(self.ldr_train), loss.item()))\n",
        "                batch_loss.append(loss.item())\n",
        "            epoch_loss.append(sum(batch_loss)/len(batch_loss))\n",
        "        return net.state_dict(), sum(epoch_loss) / len(epoch_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "WsuKl8dMbJ5s"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python\n",
        "# -*- coding: utf-8 -*-\n",
        "# Python version: 3.6\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, dim_in, dim_hidden, dim_out):\n",
        "        super(MLP, self).__init__()\n",
        "        self.layer_input = nn.Linear(dim_in, dim_hidden)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout()\n",
        "        self.layer_hidden = nn.Linear(dim_hidden, dim_out)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, x.shape[1]*x.shape[-2]*x.shape[-1])\n",
        "        x = self.layer_input(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.layer_hidden(x)\n",
        "        return x\n",
        "\n",
        "class CNNMnist(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(CNNMnist, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(args.num_channels, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, args.num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        x = x.view(-1, x.shape[1]*x.shape[2]*x.shape[3])\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "class CNNCifar(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super(CNNCifar, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, args.num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "U4VZun-qbKVr"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python\n",
        "# -*- coding: utf-8 -*-\n",
        "# Python version: 3.6\n",
        "\n",
        "import copy\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "def FedAvg(w):\n",
        "    w_avg = copy.deepcopy(w[0])\n",
        "    for k in w_avg.keys():\n",
        "        for i in range(1, len(w)):\n",
        "            w_avg[k] += w[i][k]\n",
        "        w_avg[k] = torch.div(w_avg[k], len(w))\n",
        "    return w_avg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "155W8k7mbNM9"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python\n",
        "# -*- coding: utf-8 -*-\n",
        "# @python: 3.6\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def test_img(net_g, datatest, args):\n",
        "    net_g.eval()\n",
        "    # testing\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    data_loader = DataLoader(datatest, batch_size=args.bs)\n",
        "    l = len(data_loader)\n",
        "    for idx, (data, target) in enumerate(data_loader):\n",
        "        if args.gpu != -1:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        log_probs = net_g(data)\n",
        "        # sum up batch loss\n",
        "        test_loss += F.cross_entropy(log_probs, target, reduction='sum').item()\n",
        "        # get the index of the max log-probability\n",
        "        y_pred = log_probs.data.max(1, keepdim=True)[1]\n",
        "        correct += y_pred.eq(target.data.view_as(y_pred)).long().cpu().sum()\n",
        "\n",
        "    test_loss /= len(data_loader.dataset)\n",
        "    accuracy = 100.00 * correct / len(data_loader.dataset)\n",
        "    if args.verbose:\n",
        "        print('\\nTest set: Average loss: {:.4f} \\nAccuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "            test_loss, correct, len(data_loader.dataset), accuracy))\n",
        "    return accuracy, test_loss"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyPTvNgH36kCyqWdAC4mLDaZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}