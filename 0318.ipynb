{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOmVAgGjoe+VsoGbkKOvkEB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tuesmonsoleil/Dysgraphia-Classification/blob/main/resnet_for_handwriting_0318.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "k-eCIKphyfz9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define data directory\n",
        "data_dir = \"train\"\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "Dataset = os.chdir('/content/drive/My Drive/Dataset/dataSciRep_public') #切換該目錄\n",
        "os.listdir() #確認目錄內容"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIFoqErByH38",
        "outputId": "550bec7c-27f5-484a-ef12-c9b0ae1b68c3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['test',\n",
              " 'train',\n",
              " 'dataset',\n",
              " 'model_fold5.pth',\n",
              " 'model_fold1.pth',\n",
              " 'model_fold2.pth',\n",
              " 'model_fold3.pth',\n",
              " 'model_fold4.pth']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "X1zOh8QPxo2Y",
        "outputId": "c43fb12f-ac19-44c1-af85-9000317b212a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda.is_available True\n",
            "Fold 1:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 166MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 10], 8.915940761566162, loss: 0.745\n",
            "[1, 20], 6.578901529312134, loss: 0.727\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-1fd3b26e86b4>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m                     \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                     \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1330\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1293\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Определение класса RandomContoursRemovalTransform\n",
        "class RandomContoursRemovalTransform(object):\n",
        "    def __init__(self, removal_probability=0.4):\n",
        "        self.removal_probability = removal_probability\n",
        "\n",
        "    def __call__(self, img):\n",
        "        # Convert PIL image to numpy array\n",
        "        img_np = np.array(img)\n",
        "\n",
        "        # Convert RGB to Grayscale\n",
        "        gray_img = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "        # Apply threshold using Otsu's method\n",
        "        _, binary_img = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "\n",
        "        # Find contours, remove some, and draw them back onto the RGB image\n",
        "        contours, _ = cv2.findContours(binary_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        num_contours_to_remove = int(len(contours) * self.removal_probability)\n",
        "        contours_to_remove = random.sample(contours, num_contours_to_remove)\n",
        "        cv2.drawContours(img_np, contours_to_remove, -1, (255, 255, 255), -1)\n",
        "\n",
        "        return Image.fromarray(img_np)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print(\"cuda.is_available \" + str(torch.cuda.is_available()))\n",
        "    # Define data transforms\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((400, 400)),\n",
        "        RandomContoursRemovalTransform(removal_probability=0.4),\n",
        "        transforms.RandomCrop((224, 224)),\n",
        "        # transforms.RandomHorizontalFlip(),\n",
        "        # transforms.RandomVerticalFlip(p=0.5),\n",
        "        transforms.RandomRotation(3),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "        # transforms.RandomAffine(degrees=10, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
        "        # transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "\n",
        "    # Define data directory\n",
        "    data_dir = \"train\"\n",
        "    dataset = torchvision.datasets.ImageFolder(root=data_dir, transform=transform)\n",
        "\n",
        "    # Determine the number of classes in your dataset\n",
        "    num_classes = len(os.listdir(data_dir))\n",
        "\n",
        "    # Define hyperparameters\n",
        "    num_epochs = 40\n",
        "    learning_rate = 0.001\n",
        "    batch_size = 4\n",
        "\n",
        "    # Define cross-validation strategy (e.g., 5-fold)\n",
        "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "    for fold, (train_indices, val_indices) in enumerate(kf.split(range(len(dataset)), dataset.targets)):\n",
        "        print(f\"Fold {fold + 1}:\")\n",
        "\n",
        "        # Split the dataset into training and validation sets for this fold\n",
        "        train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
        "        val_dataset = torch.utils.data.Subset(dataset, val_indices)\n",
        "\n",
        "        # Create data loaders for training and validation\n",
        "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "\n",
        "        # Define the model\n",
        "        model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
        "\n",
        "        # Replace the last fully connected layer\n",
        "        # ResNet50 uses 2048 features before the final layer\n",
        "        model.fc = nn.Linear(2048, num_classes)\n",
        "\n",
        "\n",
        "        # Set the device\n",
        "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        model.to(device)\n",
        "\n",
        "        # Define the loss function and optimizer\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
        "\n",
        "        # Training loop\n",
        "        for epoch in range(num_epochs):\n",
        "            epoch_start_time = time.time()  # Capture the start time of the epoch\n",
        "            iterations_start_time = time.time()  # Capture the start time of the iteration\n",
        "\n",
        "            model.train()\n",
        "            running_loss = 0.0\n",
        "\n",
        "            for i, data in enumerate(train_loader, 0):\n",
        "                inputs, labels = data\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                running_loss += loss.item()\n",
        "\n",
        "                if i % 10 == 9:\n",
        "                    iterations_delta_time = time.time() - iterations_start_time  # Calculate the time difference\n",
        "                    iterations_start_time = time.time()\n",
        "\n",
        "                    print(f\"[{epoch + 1}, {i + 1}], {iterations_delta_time}, loss: {running_loss / 10:.3f}\")\n",
        "\n",
        "                    running_loss = 0.0\n",
        "\n",
        "            # Validation loop\n",
        "            model.eval()\n",
        "            y_true = []\n",
        "            y_pred = []\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for data in val_loader:\n",
        "                    images, labels = data\n",
        "                    images, labels = images.to(device), labels.to(device)\n",
        "                    outputs = model(images)\n",
        "                    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "                    y_true.extend(labels.cpu().numpy())\n",
        "                    y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "            f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "            epoch_delta_time = time.time() - epoch_start_time  # Calculate the time difference\n",
        "\n",
        "            print(f\"F1 Score (Fold {fold + 1}, Epoch {epoch + 1}, sec {epoch_delta_time}): {f1:.4f}\")\n",
        "\n",
        "        # После обучения модели и вычисления метрик для текущего fold\n",
        "        precision = precision_score(y_true, y_pred, average='weighted')\n",
        "        recall = recall_score(y_true, y_pred, average='weighted')\n",
        "        f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "        # Визуализация метрик для текущего fold\n",
        "        metrics = [precision, recall, f1]\n",
        "        metric_names = ['Precision', 'Recall', 'F1 Score']\n",
        "        plt.figure(figsize=(7, 4))\n",
        "        plt.bar(metric_names, metrics, color=['blue', 'orange', 'green'])\n",
        "        plt.title(f'Metrics for Fold {fold + 1}')\n",
        "        plt.ylim([0, 1])\n",
        "        for i, v in enumerate(metrics):\n",
        "            plt.text(i, v + 0.02, f\"{v:.2f}\", ha='center', va='bottom')\n",
        "        plt.show(block=False)\n",
        "\n",
        "        # После обучения модели и вычисления метрик для текущего fold\n",
        "        model.eval()\n",
        "        y_true = []\n",
        "        y_scores = []  # Список для хранения вероятностей классов\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for data in val_loader:\n",
        "                images, labels = data\n",
        "                images = images.to(device)\n",
        "                outputs = model(images)\n",
        "                probabilities = torch.nn.functional.softmax(outputs, dim=1)  # Вычисление вероятностей\n",
        "                y_true.extend(labels.cpu().numpy())\n",
        "                y_scores.extend(probabilities[:, 1].cpu().numpy())  # Вероятности класса 1\n",
        "\n",
        "        # Вычисление ROC-кривой и AUC\n",
        "        fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        # Построение ROC-кривой\n",
        "        plt.figure()\n",
        "        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title(f'Receiver Operating Characteristic (Fold {fold + 1})')\n",
        "        plt.legend(loc='lower right')\n",
        "        plt.show(block=False)\n",
        "\n",
        "        # Save the model for this fold if needed\n",
        "        torch.save(model.state_dict(), f\"model_fold{fold + 1}.pth\")\n",
        "\n",
        "    input(\"Press Enter to exit...\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Определение класса RandomContoursRemovalTransform\n",
        "class RandomContoursRemovalTransform(object):\n",
        "    def __init__(self, removal_probability=0.4):\n",
        "        self.removal_probability = removal_probability\n",
        "\n",
        "    def __call__(self, img):\n",
        "        # Convert PIL image to numpy array\n",
        "        img_np = np.array(img)\n",
        "\n",
        "        # Convert RGB to Grayscale\n",
        "        gray_img = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "        # Apply threshold using Otsu's method\n",
        "        _, binary_img = cv2.threshold(gray_img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "\n",
        "        # Find contours, remove some, and draw them back onto the RGB image\n",
        "        contours, _ = cv2.findContours(binary_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        num_contours_to_remove = int(len(contours) * self.removal_probability)\n",
        "        contours_to_remove = random.sample(contours, num_contours_to_remove)\n",
        "        cv2.drawContours(img_np, contours_to_remove, -1, (255, 255, 255), -1)\n",
        "\n",
        "        return Image.fromarray(img_np)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print(\"cuda.is_available \" + str(torch.cuda.is_available()))\n",
        "    # Define data transforms\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((400, 400)),\n",
        "        RandomContoursRemovalTransform(removal_probability=0.4),\n",
        "        transforms.RandomCrop((224, 224)),\n",
        "        # transforms.RandomHorizontalFlip(),\n",
        "        # transforms.RandomVerticalFlip(p=0.5),\n",
        "        transforms.RandomRotation(3),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "        # transforms.RandomAffine(degrees=10, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
        "        # transforms.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vy0NFNqyvaoe",
        "outputId": "feae8325-d7cd-46c8-b277-0491821e15cf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda.is_available True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Define the range of parameters to test\n",
        "learning_rate_range = [0.0001, 0.001, 0.01]\n",
        "removal_probability_range = [0.2, 0.4, 0.6]\n",
        "\n",
        "# Define the number of experiments to run\n",
        "num_experiments = 10\n",
        "\n",
        "for experiment in range(num_experiments):\n",
        "    # Randomly select parameters from the defined ranges\n",
        "    learning_rate = random.choice(learning_rate_range)\n",
        "    removal_probability = random.choice(removal_probability_range)\n",
        "\n",
        "    # Define data transforms with the selected removal probability\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((400, 400)),\n",
        "        RandomContoursRemovalTransform(removal_probability=removal_probability),\n",
        "        transforms.RandomCrop((224, 224)),\n",
        "        transforms.RandomRotation(3),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    # Print the selected parameters for this experiment\n",
        "    print(f\"Experiment {experiment + 1}:\")\n",
        "    print(f\"Learning Rate: {learning_rate}\")\n",
        "    print(f\"Removal Probability: {removal_probability}\")\n",
        "\n",
        "    # Define the model and other parameters as before\n",
        "\n",
        "    # Training loop and evaluation as before\n",
        "\n",
        "    print(\"Experiment completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVCkicnQ6hMO",
        "outputId": "8849e79b-a66d-4c1e-b90a-2d3ab71ce06c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment 1:\n",
            "Learning Rate: 0.0001\n",
            "Removal Probability: 0.4\n",
            "Experiment completed.\n",
            "Experiment 2:\n",
            "Learning Rate: 0.01\n",
            "Removal Probability: 0.4\n",
            "Experiment completed.\n",
            "Experiment 3:\n",
            "Learning Rate: 0.001\n",
            "Removal Probability: 0.2\n",
            "Experiment completed.\n",
            "Experiment 4:\n",
            "Learning Rate: 0.0001\n",
            "Removal Probability: 0.2\n",
            "Experiment completed.\n",
            "Experiment 5:\n",
            "Learning Rate: 0.01\n",
            "Removal Probability: 0.6\n",
            "Experiment completed.\n",
            "Experiment 6:\n",
            "Learning Rate: 0.0001\n",
            "Removal Probability: 0.2\n",
            "Experiment completed.\n",
            "Experiment 7:\n",
            "Learning Rate: 0.001\n",
            "Removal Probability: 0.6\n",
            "Experiment completed.\n",
            "Experiment 8:\n",
            "Learning Rate: 0.01\n",
            "Removal Probability: 0.2\n",
            "Experiment completed.\n",
            "Experiment 9:\n",
            "Learning Rate: 0.0001\n",
            "Removal Probability: 0.4\n",
            "Experiment completed.\n",
            "Experiment 10:\n",
            "Learning Rate: 0.0001\n",
            "Removal Probability: 0.2\n",
            "Experiment completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def test_model(model_path, test_data_dir):\n",
        "    # Load the saved model\n",
        "    model = resnet50()\n",
        "    num_classes = len(os.listdir(test_data_dir))\n",
        "    model.fc = nn.Linear(2048, num_classes)\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # Define test transform\n",
        "    test_transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),  # Resize to the same size used in training\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    batch_size = 4\n",
        "\n",
        "    # Load test data\n",
        "    test_dataset = torchvision.datasets.ImageFolder(root=test_data_dir, transform=test_transform)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "            y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "    # Calculate F1 score and accuracy\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    # Example usage:\n",
        "    test_model(model_path=\"model_fold3.pth\", test_data_dir=\"test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZW12y7Uf4lxc",
        "outputId": "a909e422-f812-4098-febc-3f1904a34c72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score: 0.3333\n",
            "Accuracy: 0.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ">>> from sklearn.datasets import make_classification\n",
        ">>> from sklearn.ensemble import RandomForestClassifier\n",
        ">>> from sklearn.experimental import enable_halving_search_cv  # noqa\n",
        ">>> from sklearn.model_selection import HalvingGridSearchCV\n",
        ">>> import pandas as pd\n",
        ">>>\n",
        ">>> param_grid = {'max_depth': [3, 5, 10],\n",
        "...         'min_samples_split': [2, 5, 10]}\n",
        ">>> base_estimator = RandomForestClassifier(random_state=0)\n",
        ">>> X, y = make_classification(n_samples=1000, random_state=0)\n",
        ">>> sh = HalvingGridSearchCV(base_estimator, param_grid, cv=5,\n",
        "...                          factor=2, resource='n_estimators',\n",
        "...                          max_resources=30).fit(X, y)\n",
        ">>> sh.best_estimator_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "bHxq2M8C5HX7",
        "outputId": "55b5e036-df0f-4c08-ac64-fc2236aeb0c2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(max_depth=5, n_estimators=24, random_state=0)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=5, n_estimators=24, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=5, n_estimators=24, random_state=0)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install protobuf==3.20.3\n",
        "!pip install --upgrade tensorflow-metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqzxy8KkCW1Z",
        "outputId": "04b66d00-9093-4740-d8a3-c03ac98b499a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: protobuf==3.20.3 in /usr/local/lib/python3.10/dist-packages (3.20.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (1.14.0)\n",
            "Requirement already satisfied: absl-py<2.0.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata) (1.4.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata) (1.63.0)\n",
            "Requirement already satisfied: protobuf<4.21,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata) (3.20.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vsPSCrWG_5Q2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "feb5086a-7968-4c91-d334-faeaad2cc98d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.0/235.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 4.25.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q flwr[simulation] torch torchvision scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LRgr7dtu_5Q3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73970edf-c617-43a2-8048-800bc21f63fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on cpu using PyTorch 2.2.1+cu121 and Flower 1.7.0\n"
          ]
        }
      ],
      "source": [
        "from collections import OrderedDict\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.datasets import CIFAR10\n",
        "\n",
        "import flwr as fl\n",
        "\n",
        "DEVICE = torch.device(\"cpu\")  # Try \"cuda\" to train on GPU\n",
        "print(\n",
        "    f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "wFYBpUAJ_5Q3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c23e776-0a93-4b2c-f1e3-b59ce5d5b939"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "NUM_CLIENTS = 2\n",
        "\n",
        "\n",
        "def load_datasets(num_clients: int):\n",
        "    # Download and transform CIFAR-10 (train and test)\n",
        "    transform = transforms.Compose(\n",
        "        [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        "    )\n",
        "    trainset = CIFAR10(\"./dataset\", train=True, download=True, transform=transform)\n",
        "    testset = CIFAR10(\"./dataset\", train=False, download=True, transform=transform)\n",
        "\n",
        "    # Split training set into `num_clients` partitions to simulate different local datasets\n",
        "    partition_size = len(trainset) // num_clients\n",
        "    lengths = [partition_size] * num_clients\n",
        "    datasets = random_split(trainset, lengths, torch.Generator().manual_seed(42))\n",
        "\n",
        "    # Split each partition into train/val and create DataLoader\n",
        "    trainloaders = []\n",
        "    valloaders = []\n",
        "    for ds in datasets:\n",
        "        len_val = len(ds) // 20  # 20 % validation set\n",
        "        len_train = len(ds) - len_val\n",
        "        lengths = [len_train, len_val]\n",
        "        ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
        "        trainloaders.append(DataLoader(ds_train, batch_size=40, shuffle=True))\n",
        "        valloaders.append(DataLoader(ds_val, batch_size=40))\n",
        "    testloader = DataLoader(testset, batch_size=40)\n",
        "    return trainloaders, valloaders, testloader\n",
        "\n",
        "\n",
        "trainloaders, valloaders, testloader = load_datasets(NUM_CLIENTS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "XxfBEYsw_5Q4"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def get_parameters(net) -> List[np.ndarray]:\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
        "\n",
        "\n",
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "\n",
        "def train(net, trainloader, epochs: int):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters())\n",
        "    net.train()\n",
        "    for epoch in range(epochs):\n",
        "        correct, total, epoch_loss = 0, 0, 0.0\n",
        "        for images, labels in trainloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(images)\n",
        "            loss = criterion(net(images), labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # Metrics\n",
        "            epoch_loss += loss\n",
        "            total += labels.size(0)\n",
        "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "        epoch_loss /= len(trainloader.dataset)\n",
        "        epoch_acc = correct / total\n",
        "        print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
        "\n",
        "\n",
        "def test(net, testloader):\n",
        "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    loss /= len(testloader.dataset)\n",
        "    accuracy = correct / total\n",
        "    return loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "xZ7Wmglw_5Q4"
      },
      "outputs": [],
      "source": [
        "class FlowerNumPyClient(fl.client.NumPyClient):\n",
        "    def __init__(self, cid, net, trainloader, valloader):\n",
        "        self.cid = cid\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        print(f\"[Client {self.cid}] get_parameters\")\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        print(f\"[Client {self.cid}] fit, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        train(self.net, self.trainloader, epochs=1)\n",
        "        return get_parameters(self.net), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        loss, accuracy = test(self.net, self.valloader)\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
        "\n",
        "\n",
        "def numpyclient_fn(cid) -> FlowerNumPyClient:\n",
        "    net = Net().to(DEVICE)\n",
        "    trainloader = trainloaders[int(cid)]\n",
        "    valloader = valloaders[int(cid)]\n",
        "    return FlowerNumPyClient(cid, net, trainloader, valloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "7A4WJxy0_5Q4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7686e4b0-c2df-49d8-ff7b-4e6d4ed1b659"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-03-18 04:11:13,182 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=5, round_timeout=None)\n",
            "INFO:flwr:Starting Flower simulation, config: ServerConfig(num_rounds=5, round_timeout=None)\n",
            "\u001b[2m\u001b[36m(pid=6355)\u001b[0m 2024-03-18 04:11:11.889062: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=6355)\u001b[0m 2024-03-18 04:11:11.889108: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=6355)\u001b[0m 2024-03-18 04:11:11.890833: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-18 04:11:17,721\tINFO worker.py:1621 -- Started a local Ray instance.\n",
            "INFO flwr 2024-03-18 04:11:19,925 | app.py:213 | Flower VCE: Ray initialized with resources: {'CPU': 2.0, 'memory': 7892877312.0, 'node:__internal_head__': 1.0, 'object_store_memory': 3946438656.0, 'GPU': 1.0, 'node:172.28.0.12': 1.0}\n",
            "INFO:flwr:Flower VCE: Ray initialized with resources: {'CPU': 2.0, 'memory': 7892877312.0, 'node:__internal_head__': 1.0, 'object_store_memory': 3946438656.0, 'GPU': 1.0, 'node:172.28.0.12': 1.0}\n",
            "INFO flwr 2024-03-18 04:11:19,932 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html\n",
            "INFO:flwr:Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html\n",
            "INFO flwr 2024-03-18 04:11:19,938 | app.py:227 | No `client_resources` specified. Using minimal resources for clients.\n",
            "INFO:flwr:No `client_resources` specified. Using minimal resources for clients.\n",
            "INFO flwr 2024-03-18 04:11:19,944 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
            "INFO:flwr:Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
            "INFO flwr 2024-03-18 04:11:19,994 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n",
            "INFO:flwr:Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n",
            "INFO flwr 2024-03-18 04:11:19,999 | server.py:89 | Initializing global parameters\n",
            "INFO:flwr:Initializing global parameters\n",
            "INFO flwr 2024-03-18 04:11:20,006 | server.py:276 | Requesting initial parameters from one random client\n",
            "INFO:flwr:Requesting initial parameters from one random client\n",
            "\u001b[2m\u001b[36m(pid=6604)\u001b[0m 2024-03-18 04:11:23.145924: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=6604)\u001b[0m 2024-03-18 04:11:23.145994: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=6604)\u001b[0m 2024-03-18 04:11:23.147787: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=6604)\u001b[0m 2024-03-18 04:11:25.085295: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO flwr 2024-03-18 04:11:36,448 | server.py:280 | Received initial parameters from one random client\n",
            "INFO:flwr:Received initial parameters from one random client\n",
            "INFO flwr 2024-03-18 04:11:36,451 | server.py:91 | Evaluating initial parameters\n",
            "INFO:flwr:Evaluating initial parameters\n",
            "INFO flwr 2024-03-18 04:11:36,454 | server.py:104 | FL starting\n",
            "INFO:flwr:FL starting\n",
            "DEBUG flwr 2024-03-18 04:11:36,456 | server.py:222 | fit_round 1: strategy sampled 2 clients (out of 2)\n",
            "DEBUG:flwr:fit_round 1: strategy sampled 2 clients (out of 2)\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=6605)\u001b[0m /usr/local/lib/python3.10/dist-packages/flwr/simulation/ray_transport/ray_actor.py:72: DeprecationWarning:  Ensure your client is of type `flwr.client.Client`. Please convert it using the `.to_client()` method before returning it in the `client_fn` you pass to `start_simulation`. We have applied this conversion on your behalf. Not returning a `Client` might trigger an error in future versions of Flower.\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=6605)\u001b[0m   client = check_clientfn_returns_client(client_fn(cid))\n",
            "\u001b[2m\u001b[36m(pid=6605)\u001b[0m 2024-03-18 04:11:23.145955: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=6605)\u001b[0m 2024-03-18 04:11:23.145994: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=6605)\u001b[0m 2024-03-18 04:11:23.147787: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=6605)\u001b[0m 2024-03-18 04:11:25.083803: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=6605)\u001b[0m [Client 0] get_parameters\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=6604)\u001b[0m /usr/local/lib/python3.10/dist-packages/flwr/simulation/ray_transport/ray_actor.py:72: DeprecationWarning:  Ensure your client is of type `flwr.client.Client`. Please convert it using the `.to_client()` method before returning it in the `client_fn` you pass to `start_simulation`. We have applied this conversion on your behalf. Not returning a `Client` might trigger an error in future versions of Flower.\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=6604)\u001b[0m   client = check_clientfn_returns_client(client_fn(cid))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=6605)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=6604)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=6605)\u001b[0m Epoch 1: train loss 0.04430663585662842, accuracy 0.34846315789473686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-18 04:12:13,559 | server.py:236 | fit_round 1 received 2 results and 0 failures\n",
            "DEBUG:flwr:fit_round 1 received 2 results and 0 failures\n",
            "WARNING flwr 2024-03-18 04:12:13,568 | fedavg.py:250 | No fit_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No fit_metrics_aggregation_fn provided\n",
            "DEBUG flwr 2024-03-18 04:12:13,572 | server.py:173 | evaluate_round 1: strategy sampled 2 clients (out of 2)\n",
            "DEBUG:flwr:evaluate_round 1: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=6604)\u001b[0m Epoch 1: train loss 0.04440232738852501, accuracy 0.34442105263157896\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=6604)\u001b[0m [Client 1] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-18 04:12:16,966 | server.py:187 | evaluate_round 1 received 2 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 1 received 2 results and 0 failures\n",
            "WARNING flwr 2024-03-18 04:12:16,969 | fedavg.py:281 | No evaluate_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No evaluate_metrics_aggregation_fn provided\n",
            "DEBUG flwr 2024-03-18 04:12:16,971 | server.py:222 | fit_round 2: strategy sampled 2 clients (out of 2)\n",
            "DEBUG:flwr:fit_round 2: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=6605)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=6605)\u001b[0m Epoch 1: train loss 0.03740325942635536, accuracy 0.45486315789473686\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=6605)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=6604)\u001b[0m [Client 0] fit, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-18 04:12:47,317 | server.py:236 | fit_round 2 received 2 results and 0 failures\n",
            "DEBUG:flwr:fit_round 2 received 2 results and 0 failures\n",
            "DEBUG flwr 2024-03-18 04:12:47,323 | server.py:173 | evaluate_round 2: strategy sampled 2 clients (out of 2)\n",
            "DEBUG:flwr:evaluate_round 2: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=6604)\u001b[0m [Client 1] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-18 04:12:50,706 | server.py:187 | evaluate_round 2 received 2 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 2 received 2 results and 0 failures\n",
            "DEBUG flwr 2024-03-18 04:12:50,712 | server.py:222 | fit_round 3: strategy sampled 2 clients (out of 2)\n",
            "DEBUG:flwr:fit_round 3: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=6605)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=6604)\u001b[0m Epoch 1: train loss 0.03750230371952057, accuracy 0.4530947368421053\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=6605)\u001b[0m Epoch 1: train loss 0.03434641286730766, accuracy 0.5011789473684211\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=6605)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=6604)\u001b[0m [Client 1] fit, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-18 04:13:19,033 | server.py:236 | fit_round 3 received 2 results and 0 failures\n",
            "DEBUG:flwr:fit_round 3 received 2 results and 0 failures\n",
            "DEBUG flwr 2024-03-18 04:13:19,042 | server.py:173 | evaluate_round 3: strategy sampled 2 clients (out of 2)\n",
            "DEBUG:flwr:evaluate_round 3: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=6604)\u001b[0m [Client 0] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-18 04:13:22,336 | server.py:187 | evaluate_round 3 received 2 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 3 received 2 results and 0 failures\n",
            "DEBUG flwr 2024-03-18 04:13:22,341 | server.py:222 | fit_round 4: strategy sampled 2 clients (out of 2)\n",
            "DEBUG:flwr:fit_round 4: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=6605)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=6604)\u001b[0m Epoch 1: train loss 0.0342472568154335, accuracy 0.5031157894736842\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=6605)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=6605)\u001b[0m Epoch 1: train loss 0.032107874751091, accuracy 0.5365052631578947\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=6604)\u001b[0m [Client 0] fit, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-18 04:13:50,757 | server.py:236 | fit_round 4 received 2 results and 0 failures\n",
            "DEBUG:flwr:fit_round 4 received 2 results and 0 failures\n",
            "DEBUG flwr 2024-03-18 04:13:50,766 | server.py:173 | evaluate_round 4: strategy sampled 2 clients (out of 2)\n",
            "DEBUG:flwr:evaluate_round 4: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=6604)\u001b[0m [Client 0] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-18 04:13:54,366 | server.py:187 | evaluate_round 4 received 2 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 4 received 2 results and 0 failures\n",
            "DEBUG flwr 2024-03-18 04:13:54,369 | server.py:222 | fit_round 5: strategy sampled 2 clients (out of 2)\n",
            "DEBUG:flwr:fit_round 5: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=6605)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=6604)\u001b[0m Epoch 1: train loss 0.03218267858028412, accuracy 0.5382736842105263\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=6605)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=6605)\u001b[0m Epoch 1: train loss 0.030380111187696457, accuracy 0.5666526315789474\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=6604)\u001b[0m [Client 0] fit, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-18 04:14:22,792 | server.py:236 | fit_round 5 received 2 results and 0 failures\n",
            "DEBUG:flwr:fit_round 5 received 2 results and 0 failures\n",
            "DEBUG flwr 2024-03-18 04:14:22,809 | server.py:173 | evaluate_round 5: strategy sampled 2 clients (out of 2)\n",
            "DEBUG:flwr:evaluate_round 5: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=6604)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=6604)\u001b[0m Epoch 1: train loss 0.03059961460530758, accuracy 0.5634947368421053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-18 04:14:27,798 | server.py:187 | evaluate_round 5 received 2 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 5 received 2 results and 0 failures\n",
            "INFO flwr 2024-03-18 04:14:27,803 | server.py:153 | FL finished in 171.34669057799988\n",
            "INFO:flwr:FL finished in 171.34669057799988\n",
            "INFO flwr 2024-03-18 04:14:27,805 | app.py:226 | app_fit: losses_distributed [(1, 0.041935783529281616), (2, 0.03523915634155274), (3, 0.03318497042655945), (4, 0.03071807141304016), (5, 0.029954172039031984)]\n",
            "INFO:flwr:app_fit: losses_distributed [(1, 0.041935783529281616), (2, 0.03523915634155274), (3, 0.03318497042655945), (4, 0.03071807141304016), (5, 0.029954172039031984)]\n",
            "INFO flwr 2024-03-18 04:14:27,807 | app.py:227 | app_fit: metrics_distributed_fit {}\n",
            "INFO:flwr:app_fit: metrics_distributed_fit {}\n",
            "INFO flwr 2024-03-18 04:14:27,808 | app.py:228 | app_fit: metrics_distributed {}\n",
            "INFO:flwr:app_fit: metrics_distributed {}\n",
            "INFO flwr 2024-03-18 04:14:27,810 | app.py:229 | app_fit: losses_centralized []\n",
            "INFO:flwr:app_fit: losses_centralized []\n",
            "INFO flwr 2024-03-18 04:14:27,812 | app.py:230 | app_fit: metrics_centralized {}\n",
            "INFO:flwr:app_fit: metrics_centralized {}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "History (loss, distributed):\n",
              "\tround 1: 0.041935783529281616\n",
              "\tround 2: 0.03523915634155274\n",
              "\tround 3: 0.03318497042655945\n",
              "\tround 4: 0.03071807141304016\n",
              "\tround 5: 0.029954172039031984"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Specify client resources if you need GPU (defaults to 1 CPU and 0 GPU)\n",
        "client_resources = None\n",
        "if DEVICE.type == \"cuda\":\n",
        "    client_resources = {\"num_gpus\": 1}\n",
        "\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=numpyclient_fn,\n",
        "    num_clients=2,\n",
        "    config=fl.server.ServerConfig(num_rounds=5),\n",
        "    client_resources=client_resources,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "wvRHP4SY_5Q5"
      },
      "outputs": [],
      "source": [
        "from flwr.common import (\n",
        "    Code,\n",
        "    EvaluateIns,\n",
        "    EvaluateRes,\n",
        "    FitIns,\n",
        "    FitRes,\n",
        "    GetParametersIns,\n",
        "    GetParametersRes,\n",
        "    Status,\n",
        "    ndarrays_to_parameters,\n",
        "    parameters_to_ndarrays,\n",
        ")\n",
        "\n",
        "\n",
        "class FlowerClient(fl.client.Client):\n",
        "    def __init__(self, cid, net, trainloader, valloader):\n",
        "        self.cid = cid\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "\n",
        "    def get_parameters(self, ins: GetParametersIns) -> GetParametersRes:\n",
        "        print(f\"[Client {self.cid}] get_parameters\")\n",
        "\n",
        "        # Get parameters as a list of NumPy ndarray's\n",
        "        ndarrays: List[np.ndarray] = get_parameters(self.net)\n",
        "\n",
        "        # Serialize ndarray's into a Parameters object\n",
        "        parameters = ndarrays_to_parameters(ndarrays)\n",
        "\n",
        "        # Build and return response\n",
        "        status = Status(code=Code.OK, message=\"Success\")\n",
        "        return GetParametersRes(\n",
        "            status=status,\n",
        "            parameters=parameters,\n",
        "        )\n",
        "\n",
        "    def fit(self, ins: FitIns) -> FitRes:\n",
        "        print(f\"[Client {self.cid}] fit, config: {ins.config}\")\n",
        "\n",
        "        # Deserialize parameters to NumPy ndarray's\n",
        "        parameters_original = ins.parameters\n",
        "        ndarrays_original = parameters_to_ndarrays(parameters_original)\n",
        "\n",
        "        # Update local model, train, get updated parameters\n",
        "        set_parameters(self.net, ndarrays_original)\n",
        "        train(self.net, self.trainloader, epochs=10)\n",
        "        ndarrays_updated = get_parameters(self.net)\n",
        "\n",
        "        # Serialize ndarray's into a Parameters object\n",
        "        parameters_updated = ndarrays_to_parameters(ndarrays_updated)\n",
        "\n",
        "        # Build and return response\n",
        "        status = Status(code=Code.OK, message=\"Success\")\n",
        "        return FitRes(\n",
        "            status=status,\n",
        "            parameters=parameters_updated,\n",
        "            num_examples=len(self.trainloader),\n",
        "            metrics={},\n",
        "        )\n",
        "\n",
        "    def evaluate(self, ins: EvaluateIns) -> EvaluateRes:\n",
        "        print(f\"[Client {self.cid}] evaluate, config: {ins.config}\")\n",
        "\n",
        "        # Deserialize parameters to NumPy ndarray's\n",
        "        parameters_original = ins.parameters\n",
        "        ndarrays_original = parameters_to_ndarrays(parameters_original)\n",
        "\n",
        "        set_parameters(self.net, ndarrays_original)\n",
        "        loss, accuracy = test(self.net, self.valloader)\n",
        "        # return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
        "\n",
        "        # Build and return response\n",
        "        status = Status(code=Code.OK, message=\"Success\")\n",
        "        return EvaluateRes(\n",
        "            status=status,\n",
        "            loss=float(loss),\n",
        "            num_examples=len(self.valloader),\n",
        "            metrics={\"accuracy\": float(accuracy)},\n",
        "        )\n",
        "\n",
        "\n",
        "def client_fn(cid) -> FlowerClient:\n",
        "    net = Net().to(DEVICE)\n",
        "    trainloader = trainloaders[int(cid)]\n",
        "    valloader = valloaders[int(cid)]\n",
        "    return FlowerClient(cid, net, trainloader, valloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "S-bPvwjt_5Q5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9fa70e9-46e7-4b0b-bf93-10fc5ef98826"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-03-18 04:16:50,249 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=5, round_timeout=None)\n",
            "INFO:flwr:Starting Flower simulation, config: ServerConfig(num_rounds=5, round_timeout=None)\n",
            "2024-03-18 04:16:55,367\tINFO worker.py:1621 -- Started a local Ray instance.\n",
            "INFO flwr 2024-03-18 04:16:58,188 | app.py:213 | Flower VCE: Ray initialized with resources: {'node:__internal_head__': 1.0, 'object_store_memory': 3921115545.0, 'node:172.28.0.12': 1.0, 'GPU': 1.0, 'memory': 7842231092.0, 'CPU': 2.0}\n",
            "INFO:flwr:Flower VCE: Ray initialized with resources: {'node:__internal_head__': 1.0, 'object_store_memory': 3921115545.0, 'node:172.28.0.12': 1.0, 'GPU': 1.0, 'memory': 7842231092.0, 'CPU': 2.0}\n",
            "INFO flwr 2024-03-18 04:16:58,197 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html\n",
            "INFO:flwr:Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html\n",
            "INFO flwr 2024-03-18 04:16:58,200 | app.py:227 | No `client_resources` specified. Using minimal resources for clients.\n",
            "INFO:flwr:No `client_resources` specified. Using minimal resources for clients.\n",
            "INFO flwr 2024-03-18 04:16:58,203 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
            "INFO:flwr:Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
            "INFO flwr 2024-03-18 04:16:58,251 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n",
            "INFO:flwr:Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n",
            "INFO flwr 2024-03-18 04:16:58,257 | server.py:89 | Initializing global parameters\n",
            "INFO:flwr:Initializing global parameters\n",
            "INFO flwr 2024-03-18 04:16:58,261 | server.py:276 | Requesting initial parameters from one random client\n",
            "INFO:flwr:Requesting initial parameters from one random client\n",
            "\u001b[2m\u001b[36m(pid=8248)\u001b[0m 2024-03-18 04:17:01.483247: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=8248)\u001b[0m 2024-03-18 04:17:01.483336: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=8248)\u001b[0m 2024-03-18 04:17:01.485125: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=8248)\u001b[0m 2024-03-18 04:17:03.258996: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO flwr 2024-03-18 04:17:09,256 | server.py:280 | Received initial parameters from one random client\n",
            "INFO:flwr:Received initial parameters from one random client\n",
            "INFO flwr 2024-03-18 04:17:09,268 | server.py:91 | Evaluating initial parameters\n",
            "INFO:flwr:Evaluating initial parameters\n",
            "INFO flwr 2024-03-18 04:17:09,271 | server.py:104 | FL starting\n",
            "INFO:flwr:FL starting\n",
            "DEBUG flwr 2024-03-18 04:17:09,276 | server.py:222 | fit_round 1: strategy sampled 2 clients (out of 2)\n",
            "DEBUG:flwr:fit_round 1: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m [Client 1] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 1: train loss 0.04309799522161484, accuracy 0.3663157894736842\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8246)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8246)\u001b[0m Epoch 1: train loss 0.04391339793801308, accuracy 0.3512\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 2: train loss 0.03572810813784599, accuracy 0.48210526315789476\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8246)\u001b[0m Epoch 2: train loss 0.036232899874448776, accuracy 0.47646315789473687\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 3: train loss 0.03285704925656319, accuracy 0.5256\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8246)\u001b[0m Epoch 3: train loss 0.03316185250878334, accuracy 0.5205052631578947\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 4: train loss 0.030500954017043114, accuracy 0.5669052631578947\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8246)\u001b[0m Epoch 4: train loss 0.03094206191599369, accuracy 0.5536421052631579\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 5: train loss 0.028675736859440804, accuracy 0.5914526315789473\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8246)\u001b[0m Epoch 5: train loss 0.02912365086376667, accuracy 0.5829052631578947\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 6: train loss 0.02725991979241371, accuracy 0.6085473684210526\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8246)\u001b[0m Epoch 6: train loss 0.02739058993756771, accuracy 0.6107789473684211\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 7: train loss 0.02577151171863079, accuracy 0.6330105263157895\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8246)\u001b[0m Epoch 7: train loss 0.02600572071969509, accuracy 0.6287157894736842\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 8: train loss 0.02458331547677517, accuracy 0.6518315789473684\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8246)\u001b[0m Epoch 8: train loss 0.024889660999178886, accuracy 0.6469052631578948\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 9: train loss 0.023598579689860344, accuracy 0.6656842105263158\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8246)\u001b[0m Epoch 9: train loss 0.023776890709996223, accuracy 0.6635368421052632\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 10: train loss 0.022481029853224754, accuracy 0.6831578947368421\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-18 04:21:18,157 | server.py:236 | fit_round 1 received 2 results and 0 failures\n",
            "DEBUG:flwr:fit_round 1 received 2 results and 0 failures\n",
            "WARNING flwr 2024-03-18 04:21:18,165 | fedavg.py:250 | No fit_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No fit_metrics_aggregation_fn provided\n",
            "DEBUG flwr 2024-03-18 04:21:18,169 | server.py:173 | evaluate_round 1: strategy sampled 2 clients (out of 2)\n",
            "DEBUG:flwr:evaluate_round 1: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=8246)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8246)\u001b[0m Epoch 10: train loss 0.022734997794032097, accuracy 0.6771368421052631\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-18 04:21:22,923 | server.py:187 | evaluate_round 1 received 2 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 1 received 2 results and 0 failures\n",
            "WARNING flwr 2024-03-18 04:21:22,926 | fedavg.py:281 | No evaluate_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No evaluate_metrics_aggregation_fn provided\n",
            "DEBUG flwr 2024-03-18 04:21:22,929 | server.py:222 | fit_round 2: strategy sampled 2 clients (out of 2)\n",
            "DEBUG:flwr:fit_round 2: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 1: train loss 0.02901453711092472, accuracy 0.5856421052631579\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8246)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 2: train loss 0.025559091940522194, accuracy 0.6358736842105264\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 3: train loss 0.023554999381303787, accuracy 0.6624842105263158\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 4: train loss 0.021812088787555695, accuracy 0.6899368421052632\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 5: train loss 0.020534837618470192, accuracy 0.7057263157894736\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 6: train loss 0.019176024943590164, accuracy 0.7261473684210527\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 7: train loss 0.01776699349284172, accuracy 0.7474947368421052\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 8: train loss 0.016504695639014244, accuracy 0.7645052631578947\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 9: train loss 0.01536682341247797, accuracy 0.7803368421052631\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 10: train loss 0.014267323538661003, accuracy 0.7962947368421053\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-18 04:25:18,931 | server.py:236 | fit_round 2 received 2 results and 0 failures\n",
            "DEBUG:flwr:fit_round 2 received 2 results and 0 failures\n",
            "DEBUG flwr 2024-03-18 04:25:18,942 | server.py:173 | evaluate_round 2: strategy sampled 2 clients (out of 2)\n",
            "DEBUG:flwr:evaluate_round 2: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=8246)\u001b[0m [Client 0] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-18 04:25:22,159 | server.py:187 | evaluate_round 2 received 2 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 2 received 2 results and 0 failures\n",
            "DEBUG flwr 2024-03-18 04:25:22,163 | server.py:222 | fit_round 3: strategy sampled 2 clients (out of 2)\n",
            "DEBUG:flwr:fit_round 3: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8246)\u001b[0m Epoch 10: train loss 0.014351990073919296, accuracy 0.7933894736842105\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 1: train loss 0.02159704640507698, accuracy 0.6905263157894737\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8246)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 2: train loss 0.018159382045269012, accuracy 0.7397894736842106\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 3: train loss 0.016261590644717216, accuracy 0.7680842105263158\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 4: train loss 0.014762995764613152, accuracy 0.788\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 5: train loss 0.013489545322954655, accuracy 0.8071157894736842\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 6: train loss 0.012450749054551125, accuracy 0.8197473684210527\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 7: train loss 0.011243516579270363, accuracy 0.8365894736842105\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 8: train loss 0.01021007914096117, accuracy 0.8522526315789474\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 9: train loss 0.00953249353915453, accuracy 0.8625263157894737\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 10: train loss 0.00867483951151371, accuracy 0.8741052631578947\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-18 04:29:12,138 | server.py:236 | fit_round 3 received 2 results and 0 failures\n",
            "DEBUG:flwr:fit_round 3 received 2 results and 0 failures\n",
            "DEBUG flwr 2024-03-18 04:29:12,154 | server.py:173 | evaluate_round 3: strategy sampled 2 clients (out of 2)\n",
            "DEBUG:flwr:evaluate_round 3: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=8246)\u001b[0m [Client 1] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-18 04:29:16,115 | server.py:187 | evaluate_round 3 received 2 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 3 received 2 results and 0 failures\n",
            "DEBUG flwr 2024-03-18 04:29:16,118 | server.py:222 | fit_round 4: strategy sampled 2 clients (out of 2)\n",
            "DEBUG:flwr:fit_round 4: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8246)\u001b[0m Epoch 10: train loss 0.008574562147259712, accuracy 0.8792842105263158\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 1: train loss 0.018484709784388542, accuracy 0.7390315789473684\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8246)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 2: train loss 0.013765421696007252, accuracy 0.8029894736842105\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 3: train loss 0.01173902302980423, accuracy 0.8304421052631579\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 4: train loss 0.010458145290613174, accuracy 0.8482947368421052\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 5: train loss 0.00909384060651064, accuracy 0.8704421052631579\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 6: train loss 0.008348707109689713, accuracy 0.8780210526315789\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 7: train loss 0.007614985574036837, accuracy 0.8910315789473684\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 8: train loss 0.006710970774292946, accuracy 0.9064842105263158\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 9: train loss 0.006449721287935972, accuracy 0.9092210526315789\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 10: train loss 0.005979103501886129, accuracy 0.9156631578947368\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-18 04:33:04,251 | server.py:236 | fit_round 4 received 2 results and 0 failures\n",
            "DEBUG:flwr:fit_round 4 received 2 results and 0 failures\n",
            "DEBUG flwr 2024-03-18 04:33:04,259 | server.py:173 | evaluate_round 4: strategy sampled 2 clients (out of 2)\n",
            "DEBUG:flwr:evaluate_round 4: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=8246)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8246)\u001b[0m Epoch 10: train loss 0.005734382662922144, accuracy 0.9182736842105264\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-18 04:33:08,960 | server.py:187 | evaluate_round 4 received 2 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 4 received 2 results and 0 failures\n",
            "DEBUG flwr 2024-03-18 04:33:08,965 | server.py:222 | fit_round 5: strategy sampled 2 clients (out of 2)\n",
            "DEBUG:flwr:fit_round 5: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 1: train loss 0.01686750166118145, accuracy 0.7627368421052632\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8246)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 2: train loss 0.011106063611805439, accuracy 0.8365894736842105\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 3: train loss 0.009008175693452358, accuracy 0.8690947368421053\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 4: train loss 0.007434336934238672, accuracy 0.8928421052631579\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 5: train loss 0.006574426777660847, accuracy 0.9059789473684211\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 6: train loss 0.005841412115842104, accuracy 0.9169684210526315\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 7: train loss 0.005638740491122007, accuracy 0.918778947368421\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 8: train loss 0.005182020831853151, accuracy 0.9247578947368421\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 9: train loss 0.004978064447641373, accuracy 0.9300631578947368\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=8248)\u001b[0m Epoch 10: train loss 0.004493542946875095, accuracy 0.9352\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-18 04:36:57,269 | server.py:236 | fit_round 5 received 2 results and 0 failures\n",
            "DEBUG:flwr:fit_round 5 received 2 results and 0 failures\n",
            "DEBUG flwr 2024-03-18 04:36:57,277 | server.py:173 | evaluate_round 5: strategy sampled 2 clients (out of 2)\n",
            "DEBUG:flwr:evaluate_round 5: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=8246)\u001b[0m [Client 0] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-18 04:37:01,741 | server.py:187 | evaluate_round 5 received 2 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 5 received 2 results and 0 failures\n",
            "INFO flwr 2024-03-18 04:37:01,746 | server.py:153 | FL finished in 1192.470118313\n",
            "INFO:flwr:FL finished in 1192.470118313\n",
            "INFO flwr 2024-03-18 04:37:01,751 | app.py:226 | app_fit: losses_distributed [(1, 0.040528466176986695), (2, 0.029792827212810517), (3, 0.03651287430524826), (4, 0.046982044649124144), (5, 0.054707199406623844)]\n",
            "INFO:flwr:app_fit: losses_distributed [(1, 0.040528466176986695), (2, 0.029792827212810517), (3, 0.03651287430524826), (4, 0.046982044649124144), (5, 0.054707199406623844)]\n",
            "INFO flwr 2024-03-18 04:37:01,755 | app.py:227 | app_fit: metrics_distributed_fit {}\n",
            "INFO:flwr:app_fit: metrics_distributed_fit {}\n",
            "INFO flwr 2024-03-18 04:37:01,757 | app.py:228 | app_fit: metrics_distributed {}\n",
            "INFO:flwr:app_fit: metrics_distributed {}\n",
            "INFO flwr 2024-03-18 04:37:01,759 | app.py:229 | app_fit: losses_centralized []\n",
            "INFO:flwr:app_fit: losses_centralized []\n",
            "INFO flwr 2024-03-18 04:37:01,761 | app.py:230 | app_fit: metrics_centralized {}\n",
            "INFO:flwr:app_fit: metrics_centralized {}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "History (loss, distributed):\n",
              "\tround 1: 0.040528466176986695\n",
              "\tround 2: 0.029792827212810517\n",
              "\tround 3: 0.03651287430524826\n",
              "\tround 4: 0.046982044649124144\n",
              "\tround 5: 0.054707199406623844"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=2,\n",
        "    config=fl.server.ServerConfig(num_rounds=5),\n",
        "    client_resources=client_resources,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "BzC58fI3_5Q5"
      },
      "outputs": [],
      "source": [
        "from io import BytesIO\n",
        "from typing import cast\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from flwr.common.typing import NDArray, NDArrays, Parameters\n",
        "\n",
        "\n",
        "def ndarrays_to_sparse_parameters(ndarrays: NDArrays) -> Parameters:\n",
        "    \"\"\"Convert NumPy ndarrays to parameters object.\"\"\"\n",
        "    tensors = [ndarray_to_sparse_bytes(ndarray) for ndarray in ndarrays]\n",
        "    return Parameters(tensors=tensors, tensor_type=\"numpy.ndarray\")\n",
        "\n",
        "\n",
        "def sparse_parameters_to_ndarrays(parameters: Parameters) -> NDArrays:\n",
        "    \"\"\"Convert parameters object to NumPy ndarrays.\"\"\"\n",
        "    return [sparse_bytes_to_ndarray(tensor) for tensor in parameters.tensors]\n",
        "\n",
        "\n",
        "def ndarray_to_sparse_bytes(ndarray: NDArray) -> bytes:\n",
        "    \"\"\"Serialize NumPy ndarray to bytes.\"\"\"\n",
        "    bytes_io = BytesIO()\n",
        "\n",
        "    if len(ndarray.shape) > 1:\n",
        "        # We convert our ndarray into a sparse matrix\n",
        "        ndarray = torch.tensor(ndarray).to_sparse_csr()\n",
        "\n",
        "        # And send it byutilizing the sparse matrix attributes\n",
        "        # WARNING: NEVER set allow_pickle to true.\n",
        "        # Reason: loading pickled data can execute arbitrary code\n",
        "        # Source: https://numpy.org/doc/stable/reference/generated/numpy.save.html\n",
        "        np.savez(\n",
        "            bytes_io,  # type: ignore\n",
        "            crow_indices=ndarray.crow_indices(),\n",
        "            col_indices=ndarray.col_indices(),\n",
        "            values=ndarray.values(),\n",
        "            allow_pickle=False,\n",
        "        )\n",
        "    else:\n",
        "        # WARNING: NEVER set allow_pickle to true.\n",
        "        # Reason: loading pickled data can execute arbitrary code\n",
        "        # Source: https://numpy.org/doc/stable/reference/generated/numpy.save.html\n",
        "        np.save(bytes_io, ndarray, allow_pickle=False)\n",
        "    return bytes_io.getvalue()\n",
        "\n",
        "\n",
        "def sparse_bytes_to_ndarray(tensor: bytes) -> NDArray:\n",
        "    \"\"\"Deserialize NumPy ndarray from bytes.\"\"\"\n",
        "    bytes_io = BytesIO(tensor)\n",
        "    # WARNING: NEVER set allow_pickle to true.\n",
        "    # Reason: loading pickled data can execute arbitrary code\n",
        "    # Source: https://numpy.org/doc/stable/reference/generated/numpy.load.html\n",
        "    loader = np.load(bytes_io, allow_pickle=False)  # type: ignore\n",
        "\n",
        "    if \"crow_indices\" in loader:\n",
        "        # We convert our sparse matrix back to a ndarray, using the attributes we sent\n",
        "        ndarray_deserialized = (\n",
        "            torch.sparse_csr_tensor(\n",
        "                crow_indices=loader[\"crow_indices\"],\n",
        "                col_indices=loader[\"col_indices\"],\n",
        "                values=loader[\"values\"],\n",
        "            )\n",
        "            .to_dense()\n",
        "            .numpy()\n",
        "        )\n",
        "    else:\n",
        "        ndarray_deserialized = loader\n",
        "    return cast(NDArray, ndarray_deserialized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "oJ9-6I75_5Q5"
      },
      "outputs": [],
      "source": [
        "from flwr.common import (\n",
        "    Code,\n",
        "    EvaluateIns,\n",
        "    EvaluateRes,\n",
        "    FitIns,\n",
        "    FitRes,\n",
        "    GetParametersIns,\n",
        "    GetParametersRes,\n",
        "    Status,\n",
        ")\n",
        "\n",
        "\n",
        "class FlowerClient(fl.client.Client):\n",
        "    def __init__(self, cid, net, trainloader, valloader):\n",
        "        self.cid = cid\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "\n",
        "    def get_parameters(self, ins: GetParametersIns) -> GetParametersRes:\n",
        "        print(f\"[Client {self.cid}] get_parameters\")\n",
        "\n",
        "        # Get parameters as a list of NumPy ndarray's\n",
        "        ndarrays: List[np.ndarray] = get_parameters(self.net)\n",
        "\n",
        "        # Serialize ndarray's into a Parameters object using our custom function\n",
        "        parameters = ndarrays_to_sparse_parameters(ndarrays)\n",
        "\n",
        "        # Build and return response\n",
        "        status = Status(code=Code.OK, message=\"Success\")\n",
        "        return GetParametersRes(\n",
        "            status=status,\n",
        "            parameters=parameters,\n",
        "        )\n",
        "\n",
        "    def fit(self, ins: FitIns) -> FitRes:\n",
        "        print(f\"[Client {self.cid}] fit, config: {ins.config}\")\n",
        "\n",
        "        # Deserialize parameters to NumPy ndarray's using our custom function\n",
        "        parameters_original = ins.parameters\n",
        "        ndarrays_original = sparse_parameters_to_ndarrays(parameters_original)\n",
        "\n",
        "        # Update local model, train, get updated parameters\n",
        "        set_parameters(self.net, ndarrays_original)\n",
        "        train(self.net, self.trainloader, epochs=10)\n",
        "        ndarrays_updated = get_parameters(self.net)\n",
        "\n",
        "        # Serialize ndarray's into a Parameters object using our custom function\n",
        "        parameters_updated = ndarrays_to_sparse_parameters(ndarrays_updated)\n",
        "\n",
        "        # Build and return response\n",
        "        status = Status(code=Code.OK, message=\"Success\")\n",
        "        return FitRes(\n",
        "            status=status,\n",
        "            parameters=parameters_updated,\n",
        "            num_examples=len(self.trainloader),\n",
        "            metrics={},\n",
        "        )\n",
        "\n",
        "    def evaluate(self, ins: EvaluateIns) -> EvaluateRes:\n",
        "        print(f\"[Client {self.cid}] evaluate, config: {ins.config}\")\n",
        "\n",
        "        # Deserialize parameters to NumPy ndarray's using our custom function\n",
        "        parameters_original = ins.parameters\n",
        "        ndarrays_original = sparse_parameters_to_ndarrays(parameters_original)\n",
        "\n",
        "        set_parameters(self.net, ndarrays_original)\n",
        "        loss, accuracy = test(self.net, self.valloader)\n",
        "\n",
        "        # Build and return response\n",
        "        status = Status(code=Code.OK, message=\"Success\")\n",
        "        return EvaluateRes(\n",
        "            status=status,\n",
        "            loss=float(loss),\n",
        "            num_examples=len(self.valloader),\n",
        "            metrics={\"accuracy\": float(accuracy)},\n",
        "        )\n",
        "\n",
        "\n",
        "def client_fn(cid) -> FlowerClient:\n",
        "    net = Net().to(DEVICE)\n",
        "    trainloader = trainloaders[int(cid)]\n",
        "    valloader = valloaders[int(cid)]\n",
        "    return FlowerClient(cid, net, trainloader, valloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "98unXyde_5Q6"
      },
      "outputs": [],
      "source": [
        "from logging import WARNING\n",
        "from typing import Callable, Dict, List, Optional, Tuple, Union\n",
        "\n",
        "from flwr.common import FitRes, MetricsAggregationFn, NDArrays, Parameters, Scalar\n",
        "from flwr.common.logger import log\n",
        "from flwr.server.client_proxy import ClientProxy\n",
        "from flwr.server.strategy import FedAvg\n",
        "from flwr.server.strategy.aggregate import aggregate\n",
        "\n",
        "WARNING_MIN_AVAILABLE_CLIENTS_TOO_LOW = \"\"\"\n",
        "Setting `min_available_clients` lower than `min_fit_clients` or\n",
        "`min_evaluate_clients` can cause the server to fail when there are too few clients\n",
        "connected to the server. `min_available_clients` must be set to a value larger\n",
        "than or equal to the values of `min_fit_clients` and `min_evaluate_clients`.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class FedSparse(FedAvg):\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        fraction_fit: float = 1.0,\n",
        "        fraction_evaluate: float = 1.0,\n",
        "        min_fit_clients: int = 2,\n",
        "        min_evaluate_clients: int = 2,\n",
        "        min_available_clients: int = 2,\n",
        "        evaluate_fn: Optional[\n",
        "            Callable[\n",
        "                [int, NDArrays, Dict[str, Scalar]],\n",
        "                Optional[Tuple[float, Dict[str, Scalar]]],\n",
        "            ]\n",
        "        ] = None,\n",
        "        on_fit_config_fn: Optional[Callable[[int], Dict[str, Scalar]]] = None,\n",
        "        on_evaluate_config_fn: Optional[Callable[[int], Dict[str, Scalar]]] = None,\n",
        "        accept_failures: bool = True,\n",
        "        initial_parameters: Optional[Parameters] = None,\n",
        "        fit_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
        "        evaluate_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
        "    ) -> None:\n",
        "        \"\"\"Custom FedAvg strategy with sparse matrices.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        fraction_fit : float, optional\n",
        "            Fraction of clients used during training. Defaults to 0.1.\n",
        "        fraction_evaluate : float, optional\n",
        "            Fraction of clients used during validation. Defaults to 0.1.\n",
        "        min_fit_clients : int, optional\n",
        "            Minimum number of clients used during training. Defaults to 2.\n",
        "        min_evaluate_clients : int, optional\n",
        "            Minimum number of clients used during validation. Defaults to 2.\n",
        "        min_available_clients : int, optional\n",
        "            Minimum number of total clients in the system. Defaults to 2.\n",
        "        evaluate_fn : Optional[Callable[[int, NDArrays, Dict[str, Scalar]], Optional[Tuple[float, Dict[str, Scalar]]]]]\n",
        "            Optional function used for validation. Defaults to None.\n",
        "        on_fit_config_fn : Callable[[int], Dict[str, Scalar]], optional\n",
        "            Function used to configure training. Defaults to None.\n",
        "        on_evaluate_config_fn : Callable[[int], Dict[str, Scalar]], optional\n",
        "            Function used to configure validation. Defaults to None.\n",
        "        accept_failures : bool, optional\n",
        "            Whether or not accept rounds containing failures. Defaults to True.\n",
        "        initial_parameters : Parameters, optional\n",
        "            Initial global model parameters.\n",
        "        \"\"\"\n",
        "\n",
        "        if (\n",
        "            min_fit_clients > min_available_clients\n",
        "            or min_evaluate_clients > min_available_clients\n",
        "        ):\n",
        "            log(WARNING, WARNING_MIN_AVAILABLE_CLIENTS_TOO_LOW)\n",
        "\n",
        "        super().__init__(\n",
        "            fraction_fit=fraction_fit,\n",
        "            fraction_evaluate=fraction_evaluate,\n",
        "            min_fit_clients=min_fit_clients,\n",
        "            min_evaluate_clients=min_evaluate_clients,\n",
        "            min_available_clients=min_available_clients,\n",
        "            evaluate_fn=evaluate_fn,\n",
        "            on_fit_config_fn=on_fit_config_fn,\n",
        "            on_evaluate_config_fn=on_evaluate_config_fn,\n",
        "            accept_failures=accept_failures,\n",
        "            initial_parameters=initial_parameters,\n",
        "            fit_metrics_aggregation_fn=fit_metrics_aggregation_fn,\n",
        "            evaluate_metrics_aggregation_fn=evaluate_metrics_aggregation_fn,\n",
        "        )\n",
        "\n",
        "    def evaluate(\n",
        "        self, server_round: int, parameters: Parameters\n",
        "    ) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
        "        \"\"\"Evaluate model parameters using an evaluation function.\"\"\"\n",
        "        if self.evaluate_fn is None:\n",
        "            # No evaluation function provided\n",
        "            return None\n",
        "\n",
        "        # We deserialize using our custom method\n",
        "        parameters_ndarrays = sparse_parameters_to_ndarrays(parameters)\n",
        "\n",
        "        eval_res = self.evaluate_fn(server_round, parameters_ndarrays, {})\n",
        "        if eval_res is None:\n",
        "            return None\n",
        "        loss, metrics = eval_res\n",
        "        return loss, metrics\n",
        "\n",
        "    def aggregate_fit(\n",
        "        self,\n",
        "        server_round: int,\n",
        "        results: List[Tuple[ClientProxy, FitRes]],\n",
        "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
        "    ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
        "        \"\"\"Aggregate fit results using weighted average.\"\"\"\n",
        "        if not results:\n",
        "            return None, {}\n",
        "        # Do not aggregate if there are failures and failures are not accepted\n",
        "        if not self.accept_failures and failures:\n",
        "            return None, {}\n",
        "\n",
        "        # We deserialize each of the results with our custom method\n",
        "        weights_results = [\n",
        "            (sparse_parameters_to_ndarrays(fit_res.parameters), fit_res.num_examples)\n",
        "            for _, fit_res in results\n",
        "        ]\n",
        "\n",
        "        # We serialize the aggregated result using our custom method\n",
        "        parameters_aggregated = ndarrays_to_sparse_parameters(\n",
        "            aggregate(weights_results)\n",
        "        )\n",
        "\n",
        "        # Aggregate custom metrics if aggregation fn was provided\n",
        "        metrics_aggregated = {}\n",
        "        if self.fit_metrics_aggregation_fn:\n",
        "            fit_metrics = [(res.num_examples, res.metrics) for _, res in results]\n",
        "            metrics_aggregated = self.fit_metrics_aggregation_fn(fit_metrics)\n",
        "        elif server_round == 1:  # Only log this warning once\n",
        "            log(WARNING, \"No fit_metrics_aggregation_fn provided\")\n",
        "\n",
        "        return parameters_aggregated, metrics_aggregated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "30myBDgy_5Q6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04909ab8-51bd-4d41-ecc7-e9eb7e51a953"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2024-03-18 04:44:18,256 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=5, round_timeout=None)\n",
            "INFO:flwr:Starting Flower simulation, config: ServerConfig(num_rounds=5, round_timeout=None)\n",
            "2024-03-18 04:44:22,845\tINFO worker.py:1621 -- Started a local Ray instance.\n",
            "INFO flwr 2024-03-18 04:44:25,986 | app.py:213 | Flower VCE: Ray initialized with resources: {'object_store_memory': 3919207219.0, 'memory': 7838414439.0, 'GPU': 1.0, 'node:172.28.0.12': 1.0, 'CPU': 2.0, 'node:__internal_head__': 1.0}\n",
            "INFO:flwr:Flower VCE: Ray initialized with resources: {'object_store_memory': 3919207219.0, 'memory': 7838414439.0, 'GPU': 1.0, 'node:172.28.0.12': 1.0, 'CPU': 2.0, 'node:__internal_head__': 1.0}\n",
            "INFO flwr 2024-03-18 04:44:25,992 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html\n",
            "INFO:flwr:Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html\n",
            "INFO flwr 2024-03-18 04:44:25,998 | app.py:227 | No `client_resources` specified. Using minimal resources for clients.\n",
            "INFO:flwr:No `client_resources` specified. Using minimal resources for clients.\n",
            "INFO flwr 2024-03-18 04:44:26,002 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
            "INFO:flwr:Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
            "INFO flwr 2024-03-18 04:44:26,073 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n",
            "INFO:flwr:Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n",
            "INFO flwr 2024-03-18 04:44:26,076 | server.py:89 | Initializing global parameters\n",
            "INFO:flwr:Initializing global parameters\n",
            "INFO flwr 2024-03-18 04:44:26,081 | server.py:276 | Requesting initial parameters from one random client\n",
            "INFO:flwr:Requesting initial parameters from one random client\n",
            "\u001b[2m\u001b[36m(pid=15361)\u001b[0m 2024-03-18 04:44:29.136118: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=15361)\u001b[0m 2024-03-18 04:44:29.136180: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=15361)\u001b[0m 2024-03-18 04:44:29.137950: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=15361)\u001b[0m 2024-03-18 04:44:30.864738: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO flwr 2024-03-18 04:44:35,776 | server.py:280 | Received initial parameters from one random client\n",
            "INFO:flwr:Received initial parameters from one random client\n",
            "INFO flwr 2024-03-18 04:44:35,778 | server.py:91 | Evaluating initial parameters\n",
            "INFO:flwr:Evaluating initial parameters\n",
            "INFO flwr 2024-03-18 04:44:35,784 | server.py:104 | FL starting\n",
            "INFO:flwr:FL starting\n",
            "DEBUG flwr 2024-03-18 04:44:35,787 | server.py:222 | fit_round 1: strategy sampled 2 clients (out of 2)\n",
            "DEBUG:flwr:fit_round 1: strategy sampled 2 clients (out of 2)\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m <ipython-input-20-77ba978efaa6>:26: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
            "\u001b[2m\u001b[36m(pid=15360)\u001b[0m 2024-03-18 04:44:29.262191: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=15360)\u001b[0m 2024-03-18 04:44:29.262243: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=15360)\u001b[0m 2024-03-18 04:44:29.263960: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m [Client 1] get_parameters\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m [Client 1] fit, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=15360)\u001b[0m 2024-03-18 04:44:30.968803: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15360)\u001b[0m <ipython-input-20-77ba978efaa6>:58: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 1: train loss 0.044156208634376526, accuracy 0.3472421052631579\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15360)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15360)\u001b[0m Epoch 1: train loss 0.04476514831185341, accuracy 0.33789473684210525\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 2: train loss 0.03628561273217201, accuracy 0.4685894736842105\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 3: train loss 0.0328485481441021, accuracy 0.5261052631578947\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15360)\u001b[0m Epoch 3: train loss 0.03434015065431595, accuracy 0.5072421052631579\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 4: train loss 0.030695904046297073, accuracy 0.558021052631579\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 5: train loss 0.02895301766693592, accuracy 0.5873263157894737\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 6: train loss 0.02735259383916855, accuracy 0.6121684210526316\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 7: train loss 0.02609470672905445, accuracy 0.6266947368421053\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 8: train loss 0.024919020012021065, accuracy 0.647578947368421\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 9: train loss 0.023904260247945786, accuracy 0.6650526315789473\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 10: train loss 0.022782819345593452, accuracy 0.6768842105263158\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-18 04:48:42,427 | server.py:236 | fit_round 1 received 2 results and 0 failures\n",
            "DEBUG:flwr:fit_round 1 received 2 results and 0 failures\n",
            "<ipython-input-20-77ba978efaa6>:58: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
            "  torch.sparse_csr_tensor(\n",
            "WARNING flwr 2024-03-18 04:48:42,452 | <ipython-input-22-d7fec34d7b0f>:134 | No fit_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No fit_metrics_aggregation_fn provided\n",
            "DEBUG flwr 2024-03-18 04:48:42,454 | server.py:173 | evaluate_round 1: strategy sampled 2 clients (out of 2)\n",
            "DEBUG:flwr:evaluate_round 1: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=15360)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15360)\u001b[0m Epoch 10: train loss 0.02366488426923752, accuracy 0.6631157894736842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-18 04:48:46,556 | server.py:187 | evaluate_round 1 received 2 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 1 received 2 results and 0 failures\n",
            "WARNING flwr 2024-03-18 04:48:46,559 | fedavg.py:281 | No evaluate_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No evaluate_metrics_aggregation_fn provided\n",
            "DEBUG flwr 2024-03-18 04:48:46,562 | server.py:222 | fit_round 2: strategy sampled 2 clients (out of 2)\n",
            "DEBUG:flwr:fit_round 2: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 1: train loss 0.028581814840435982, accuracy 0.5904\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15360)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 2: train loss 0.025647275149822235, accuracy 0.6357894736842106\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 3: train loss 0.024218475446105003, accuracy 0.6553684210526316\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 4: train loss 0.022537944838404655, accuracy 0.6760421052631579\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 5: train loss 0.021198472008109093, accuracy 0.6986947368421053\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 6: train loss 0.01975426822900772, accuracy 0.7175157894736842\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 7: train loss 0.01871544122695923, accuracy 0.7350315789473684\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 8: train loss 0.01760498248040676, accuracy 0.7495578947368421\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 9: train loss 0.016453782096505165, accuracy 0.7656842105263157\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 10: train loss 0.015450699254870415, accuracy 0.778021052631579\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-18 04:52:38,208 | server.py:236 | fit_round 2 received 2 results and 0 failures\n",
            "DEBUG:flwr:fit_round 2 received 2 results and 0 failures\n",
            "DEBUG flwr 2024-03-18 04:52:38,235 | server.py:173 | evaluate_round 2: strategy sampled 2 clients (out of 2)\n",
            "DEBUG:flwr:evaluate_round 2: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=15360)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15360)\u001b[0m Epoch 10: train loss 0.015072904527187347, accuracy 0.7874526315789474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-18 04:52:43,067 | server.py:187 | evaluate_round 2 received 2 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 2 received 2 results and 0 failures\n",
            "DEBUG flwr 2024-03-18 04:52:43,069 | server.py:222 | fit_round 3: strategy sampled 2 clients (out of 2)\n",
            "DEBUG:flwr:fit_round 3: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 1: train loss 0.021880874410271645, accuracy 0.6886315789473684\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15360)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 2: train loss 0.01901664212346077, accuracy 0.7274947368421053\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 3: train loss 0.017143920063972473, accuracy 0.7574736842105263\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 4: train loss 0.015688590705394745, accuracy 0.7792421052631578\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 5: train loss 0.014483977109193802, accuracy 0.793978947368421\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 6: train loss 0.013188859447836876, accuracy 0.8113263157894737\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 7: train loss 0.012391122058033943, accuracy 0.8235789473684211\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 8: train loss 0.011369503103196621, accuracy 0.8359578947368421\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 9: train loss 0.010531018488109112, accuracy 0.8474947368421053\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 10: train loss 0.00985410064458847, accuracy 0.8596631578947368\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-18 04:56:32,009 | server.py:236 | fit_round 3 received 2 results and 0 failures\n",
            "DEBUG:flwr:fit_round 3 received 2 results and 0 failures\n",
            "DEBUG flwr 2024-03-18 04:56:32,035 | server.py:173 | evaluate_round 3: strategy sampled 2 clients (out of 2)\n",
            "DEBUG:flwr:evaluate_round 3: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=15360)\u001b[0m [Client 0] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-18 04:56:36,100 | server.py:187 | evaluate_round 3 received 2 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 3 received 2 results and 0 failures\n",
            "DEBUG flwr 2024-03-18 04:56:36,104 | server.py:222 | fit_round 4: strategy sampled 2 clients (out of 2)\n",
            "DEBUG:flwr:fit_round 4: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15360)\u001b[0m Epoch 10: train loss 0.009230510331690311, accuracy 0.8660210526315789\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m [Client 1] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 1: train loss 0.01841086521744728, accuracy 0.7385684210526315\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15360)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 2: train loss 0.01439446397125721, accuracy 0.7896\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 3: train loss 0.012147434055805206, accuracy 0.8242105263157895\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 4: train loss 0.010902933776378632, accuracy 0.8437473684210526\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 5: train loss 0.009682076051831245, accuracy 0.8615578947368421\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 6: train loss 0.0087997792288661, accuracy 0.8732210526315789\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 7: train loss 0.008223898708820343, accuracy 0.8813894736842105\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 8: train loss 0.0074514769949018955, accuracy 0.8949473684210526\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 9: train loss 0.006899947300553322, accuracy 0.9016\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 10: train loss 0.006222075317054987, accuracy 0.9096842105263158\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-18 05:00:24,684 | server.py:236 | fit_round 4 received 2 results and 0 failures\n",
            "DEBUG:flwr:fit_round 4 received 2 results and 0 failures\n",
            "DEBUG flwr 2024-03-18 05:00:24,707 | server.py:173 | evaluate_round 4: strategy sampled 2 clients (out of 2)\n",
            "DEBUG:flwr:evaluate_round 4: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=15360)\u001b[0m [Client 1] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-18 05:00:28,073 | server.py:187 | evaluate_round 4 received 2 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 4 received 2 results and 0 failures\n",
            "DEBUG flwr 2024-03-18 05:00:28,077 | server.py:222 | fit_round 5: strategy sampled 2 clients (out of 2)\n",
            "DEBUG:flwr:fit_round 5: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m [Client 0] fit, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15360)\u001b[0m Epoch 10: train loss 0.0063783410005271435, accuracy 0.9111578947368421\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m [Client 0] evaluate, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 1: train loss 0.016657905653119087, accuracy 0.764\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15360)\u001b[0m [Client 1] fit, config: {}\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 2: train loss 0.011475982144474983, accuracy 0.8311578947368421\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 3: train loss 0.009446724317967892, accuracy 0.8628210526315789\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 4: train loss 0.008198180235922337, accuracy 0.8821473684210527\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 5: train loss 0.007496590260416269, accuracy 0.8936\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 6: train loss 0.006812902633100748, accuracy 0.9010947368421053\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 7: train loss 0.006097478326410055, accuracy 0.9141894736842106\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 8: train loss 0.005729631520807743, accuracy 0.9177263157894737\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 9: train loss 0.005252579692751169, accuracy 0.9248\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=15361)\u001b[0m Epoch 10: train loss 0.005003069527447224, accuracy 0.9280842105263158\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-18 05:04:16,679 | server.py:236 | fit_round 5 received 2 results and 0 failures\n",
            "DEBUG:flwr:fit_round 5 received 2 results and 0 failures\n",
            "DEBUG flwr 2024-03-18 05:04:16,706 | server.py:173 | evaluate_round 5: strategy sampled 2 clients (out of 2)\n",
            "DEBUG:flwr:evaluate_round 5: strategy sampled 2 clients (out of 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=15360)\u001b[0m [Client 0] evaluate, config: {}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2024-03-18 05:04:20,071 | server.py:187 | evaluate_round 5 received 2 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 5 received 2 results and 0 failures\n",
            "INFO flwr 2024-03-18 05:04:20,074 | server.py:153 | FL finished in 1184.2869611529995\n",
            "INFO:flwr:FL finished in 1184.2869611529995\n",
            "INFO flwr 2024-03-18 05:04:20,076 | app.py:226 | app_fit: losses_distributed [(1, 0.03603267011642456), (2, 0.0305977292060852), (3, 0.035862711036205294), (4, 0.04573719992637634), (5, 0.053703244400024414)]\n",
            "INFO:flwr:app_fit: losses_distributed [(1, 0.03603267011642456), (2, 0.0305977292060852), (3, 0.035862711036205294), (4, 0.04573719992637634), (5, 0.053703244400024414)]\n",
            "INFO flwr 2024-03-18 05:04:20,078 | app.py:227 | app_fit: metrics_distributed_fit {}\n",
            "INFO:flwr:app_fit: metrics_distributed_fit {}\n",
            "INFO flwr 2024-03-18 05:04:20,080 | app.py:228 | app_fit: metrics_distributed {}\n",
            "INFO:flwr:app_fit: metrics_distributed {}\n",
            "INFO flwr 2024-03-18 05:04:20,082 | app.py:229 | app_fit: losses_centralized []\n",
            "INFO:flwr:app_fit: losses_centralized []\n",
            "INFO flwr 2024-03-18 05:04:20,084 | app.py:230 | app_fit: metrics_centralized {}\n",
            "INFO:flwr:app_fit: metrics_centralized {}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "History (loss, distributed):\n",
              "\tround 1: 0.03603267011642456\n",
              "\tround 2: 0.0305977292060852\n",
              "\tround 3: 0.035862711036205294\n",
              "\tround 4: 0.04573719992637634\n",
              "\tround 5: 0.053703244400024414"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "strategy = FedSparse()\n",
        "\n",
        "fl.simulation.start_simulation(\n",
        "    strategy=strategy,\n",
        "    client_fn=client_fn,\n",
        "    num_clients=2,\n",
        "    config=fl.server.ServerConfig(num_rounds=5),\n",
        "    client_resources=client_resources,\n",
        ")"
      ]
    }
  ]
}
